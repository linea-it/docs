{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Bem-vindo(a) \u00e0 p\u00e1gina de Documenta\u00e7\u00e3o para Usu\u00e1rios do LIneA. Este \u00e9 o local central para encontrar guias de usu\u00e1rio e documenta\u00e7\u00e3o sobre todos os servi\u00e7os e ferramentas fornecidos pelo LIneA para a comunidade astron\u00f4mica e p\u00fablico em geral. Aqui voc\u00ea tamb\u00e9m encontrar\u00e1 links para documenta\u00e7\u00e3o externa relevante. O LIneA - Laborat\u00f3rio Interinstitucional de e-Astronomia - \u00e9 um laborat\u00f3rio multiusu\u00e1rio, operado por uma organiza\u00e7\u00e3o sem fins lucrativos (Associa\u00e7\u00e3o LIneA) com apoio financeiro predominantemente proveniente do Minist\u00e9rio da Ci\u00eancia, Tecnologia e Inova\u00e7\u00e3o do Brasil. Nossa miss\u00e3o \u00e9 trabalhar em parceria com o INCT do e-Universo para apoiar a comunidade astron\u00f4mica brasileira com infraestrutura computacional e expertise em an\u00e1lise de big data para fornecer condi\u00e7\u00f5es t\u00e9cnicas para participa\u00e7\u00e3o em grandes levantamentos astron\u00f4micos, como Sloan Digital Sky Survey (SDSS) , Dark Energy Survey (DES) e Legacy Survey of Space and Time (LSST) . Para saber mais, confira o v\u00eddeo \"Conhe\u00e7a o LIneA\" no nosso canal no YouTube ou navegue no nosso Website institucional . Coment\u00e1rios, d\u00favidas, sugest\u00f5es? Se voc\u00ea encontrar algo faltando nesta documenta\u00e7\u00e3o, fique \u00e0 vontade para abrir um issue no reposit\u00f3rio de documenta\u00e7\u00e3o do LIneA no GitHub . \u00daltima atualiza\u00e7\u00e3o: 26/10/2023","title":"Home"},{"location":"faq.html","text":"Como criar par de chaves SSH \u00b6 Para acessar nosso ambiente via ssh \u00e9 preciso gerar um par de chaves seguindo os passos abaixos: Linux \u00b6 a) Para gerar o par de chaves utilize o comando abaixo em seu terminal. ssh-keygen -t rsa -b 4096 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): [pressione ENTER] Created directory '/root/.ssh'. Enter passphrase (empty for no passphrase): [digite uma senha e para confirmar pressione ENTER] Enter same passphrase again: [repita a senha e pressione ENTER] b) Ap\u00f3s voc\u00ea receber a mensagem que a chave foi gerada. Voc\u00ea pode ver os dois arquivos criados listando o conte\u00fado do diret\u00f3rio ls $HOME/.ssh id_rsa id_rsa.pub c) Ap\u00f3s as chaves geradas enviar a chave .pub para a equipe de TI via email helpdesk@linea.org.br . A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor e retornar com instru\u00e7\u00f5es para login no cluster Apollo. Aguarde o retorno de ok . Windows \u00b6 Para gerar par de chaves no sistema operacional Windows a) Baixar o aplicativo Putty e instalar. b) Acessar a pasta onde o programa foi instalado (essa instala\u00e7\u00e3o foi no Windows 10) C:\\Program File\\PuTTY (caminho pode ser diferente devido ao sistema operacional), Abra o programa Puttygen. c) Clicar em Generate (o tipo de chave mant\u00e9m como RSA ). OBS : Movimentar o ponteiro do mouse ajuda a gerar a chave mais rapidamente, pois gera bits aleat\u00f3rios . d) Par de chaves geradas com sucesso. Copiar a chave publicar para ser salva no servidor (detalhe na imagem em amarelo); Colocar uma senha na chave p\u00fablica (detalhe na imagem em azul). Ap\u00f3s copiar salve as chaves public e private no computador (detalhe na imagem em vermelho) envie a chave .pub para a equipe de TI via email helpdesk@linea.org.br . A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor. Aguarde o retorno de ok . e) Ap\u00f3s o receber o email de confirma\u00e7\u00e3o que a chave .pub foi cadastrada no servidor de acesso, fazer as configura\u00e7\u00f5es no programa Putty . Crie um atalho na \u00e1rea de trabalho, abra o PuTTY ; Coloque o Hostname login.linea.org.br. f) Ao lado esquerdo ir na op\u00e7\u00e3o SSH > Auth (detalhe em azul) > aperte em Browse (detalhe em amarelo) e escolha a chave a ser usada com exten\u00e7\u00e3o .ppk . h) Caso precise utilizar algum t\u00fanel fa\u00e7a a seguinte configura\u00e7\u00e3o. OBS: os tunnels s\u00e3o configurado conforme o que o usu\u00e1rio vai acessar Ir na op\u00e7\u00e3o Tunnels (lado esquerdo); Em Source port coloque a porta; Destination > coloque o endere\u00e7o de destino > Add. Volte ao lado esquerdo e v\u00e1 na primeira op\u00e7\u00e3o menu Session (em vermelho) coloque o nome da sessions (em amarelo) e aperte em Save (em azul) , para acessar aperte em Open .","title":"Faq"},{"location":"faq.html#como-criar-par-de-chaves-ssh","text":"Para acessar nosso ambiente via ssh \u00e9 preciso gerar um par de chaves seguindo os passos abaixos:","title":"Como criar par de chaves SSH"},{"location":"faq.html#linux","text":"a) Para gerar o par de chaves utilize o comando abaixo em seu terminal. ssh-keygen -t rsa -b 4096 Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): [pressione ENTER] Created directory '/root/.ssh'. Enter passphrase (empty for no passphrase): [digite uma senha e para confirmar pressione ENTER] Enter same passphrase again: [repita a senha e pressione ENTER] b) Ap\u00f3s voc\u00ea receber a mensagem que a chave foi gerada. Voc\u00ea pode ver os dois arquivos criados listando o conte\u00fado do diret\u00f3rio ls $HOME/.ssh id_rsa id_rsa.pub c) Ap\u00f3s as chaves geradas enviar a chave .pub para a equipe de TI via email helpdesk@linea.org.br . A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor e retornar com instru\u00e7\u00f5es para login no cluster Apollo. Aguarde o retorno de ok .","title":"Linux"},{"location":"faq.html#windows","text":"Para gerar par de chaves no sistema operacional Windows a) Baixar o aplicativo Putty e instalar. b) Acessar a pasta onde o programa foi instalado (essa instala\u00e7\u00e3o foi no Windows 10) C:\\Program File\\PuTTY (caminho pode ser diferente devido ao sistema operacional), Abra o programa Puttygen. c) Clicar em Generate (o tipo de chave mant\u00e9m como RSA ). OBS : Movimentar o ponteiro do mouse ajuda a gerar a chave mais rapidamente, pois gera bits aleat\u00f3rios . d) Par de chaves geradas com sucesso. Copiar a chave publicar para ser salva no servidor (detalhe na imagem em amarelo); Colocar uma senha na chave p\u00fablica (detalhe na imagem em azul). Ap\u00f3s copiar salve as chaves public e private no computador (detalhe na imagem em vermelho) envie a chave .pub para a equipe de TI via email helpdesk@linea.org.br . A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor. Aguarde o retorno de ok . e) Ap\u00f3s o receber o email de confirma\u00e7\u00e3o que a chave .pub foi cadastrada no servidor de acesso, fazer as configura\u00e7\u00f5es no programa Putty . Crie um atalho na \u00e1rea de trabalho, abra o PuTTY ; Coloque o Hostname login.linea.org.br. f) Ao lado esquerdo ir na op\u00e7\u00e3o SSH > Auth (detalhe em azul) > aperte em Browse (detalhe em amarelo) e escolha a chave a ser usada com exten\u00e7\u00e3o .ppk . h) Caso precise utilizar algum t\u00fanel fa\u00e7a a seguinte configura\u00e7\u00e3o. OBS: os tunnels s\u00e3o configurado conforme o que o usu\u00e1rio vai acessar Ir na op\u00e7\u00e3o Tunnels (lado esquerdo); Em Source port coloque a porta; Destination > coloque o endere\u00e7o de destino > Add. Volte ao lado esquerdo e v\u00e1 na primeira op\u00e7\u00e3o menu Session (em vermelho) coloque o nome da sessions (em amarelo) e aperte em Save (em azul) , para acessar aperte em Open .","title":"Windows"},{"location":"glossario.html","text":"Acesse aqui a lista de termos t\u00e9cnicos e acr\u00f4nimos dispon\u00edvel no nosso site.","title":"Gloss\u00e1rio"},{"location":"monitoramento.html","text":"TODO","title":"Monitoramento"},{"location":"photozserver.html","text":"TODO","title":"Photozserver"},{"location":"politicas.html","text":"Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI) \u00b6 A Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI) do LIneA define diretrizes estrat\u00e9gicas sobre como a Seguran\u00e7a da Informa\u00e7\u00e3o ser\u00e1 encarada no ambiente da associa\u00e7\u00e3o. Ela foi elaborada pelo Comit\u00ea Gestor de Seguran\u00e7a da Informa\u00e7\u00e3o (CGSI/LIneA) com o apoio do Centro de Atendimento a Incidentes de Seguran\u00e7a da RNP (CAIS/RNP), e cobre diversos aspectos da seguran\u00e7a da informa\u00e7\u00e3o, definindo papeis e responsabilidades tanto para a Associa\u00e7\u00e3o LIneA, quanto para os seus colaboradores e usu\u00e1rios. Para acessar a PSI clique aqui Incidentes de Seguran\u00e7a \u00b6 Se voc\u00ea desconfia que ocorreu algum incidente de seguran\u00e7a com sua conta, servi\u00e7o ou aplica\u00e7\u00e3o que voc\u00ea esteja utilizando voc\u00ea deve contatar o LIneA imediatamente em helpdesk@linea.org.br . Recomendamos que salve qualquer evid\u00eancia referente ao incidente (logs, mensagens, screenshots etc) e inclua quantos detalhes for poss\u00edvel no seu email para n\u00f3s. Reconhecimento de uso dos recursos computacionais do LIneA \u00b6 Por favor, reconhe\u00e7a o LIneA em suas publica\u00e7\u00f5es, por exemplo: Esta pesquisa utilizou recursos computacionais da Associa\u00e7\u00e3o Laborat\u00f3rio Interinstitucional de e-Astronomia(LIneA) com o apoio financeiro do INCT do e-Universo (Processo n.\u00ba 465376/2014-2). Pol\u00edtica de Privacidade \u00b6 Em breve Pol\u00edtica de Tratamento de Dados \u00b6 Em breve","title":"Pol\u00edticas"},{"location":"politicas.html#politica-de-seguranca-da-informacao-psi","text":"A Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI) do LIneA define diretrizes estrat\u00e9gicas sobre como a Seguran\u00e7a da Informa\u00e7\u00e3o ser\u00e1 encarada no ambiente da associa\u00e7\u00e3o. Ela foi elaborada pelo Comit\u00ea Gestor de Seguran\u00e7a da Informa\u00e7\u00e3o (CGSI/LIneA) com o apoio do Centro de Atendimento a Incidentes de Seguran\u00e7a da RNP (CAIS/RNP), e cobre diversos aspectos da seguran\u00e7a da informa\u00e7\u00e3o, definindo papeis e responsabilidades tanto para a Associa\u00e7\u00e3o LIneA, quanto para os seus colaboradores e usu\u00e1rios. Para acessar a PSI clique aqui","title":"Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI)"},{"location":"politicas.html#incidentes-de-seguranca","text":"Se voc\u00ea desconfia que ocorreu algum incidente de seguran\u00e7a com sua conta, servi\u00e7o ou aplica\u00e7\u00e3o que voc\u00ea esteja utilizando voc\u00ea deve contatar o LIneA imediatamente em helpdesk@linea.org.br . Recomendamos que salve qualquer evid\u00eancia referente ao incidente (logs, mensagens, screenshots etc) e inclua quantos detalhes for poss\u00edvel no seu email para n\u00f3s.","title":"Incidentes de Seguran\u00e7a"},{"location":"politicas.html#reconhecimento-de-uso-dos-recursos-computacionais-do-linea","text":"Por favor, reconhe\u00e7a o LIneA em suas publica\u00e7\u00f5es, por exemplo: Esta pesquisa utilizou recursos computacionais da Associa\u00e7\u00e3o Laborat\u00f3rio Interinstitucional de e-Astronomia(LIneA) com o apoio financeiro do INCT do e-Universo (Processo n.\u00ba 465376/2014-2).","title":"Reconhecimento de uso dos recursos computacionais do LIneA"},{"location":"politicas.html#politica-de-privacidade","text":"Em breve","title":"Pol\u00edtica de Privacidade"},{"location":"politicas.html#politica-de-tratamento-de-dados","text":"Em breve","title":"Pol\u00edtica de Tratamento de Dados"},{"location":"primeiros_passos.html","text":"Manual de boas-vindas \u00b6 O manual \u00e9 um compilado de informa\u00e7\u00f5es importantes sobre o LIneA para aqueles que est\u00e3o conhecendo o laborat\u00f3rio pela primeira vez. Nele podemos encontrar a miss\u00e3o, objetivos, as ferramentas para usu\u00e1rios, os servi\u00e7os de e-ci\u00eancias oferecidos, descri\u00e7\u00e3o dos perfis de usu\u00e1rios, onde buscar ajuda, os representantes das colabora\u00e7\u00f5es cient\u00edficas apoiadas pelo LIneA, maneiras de se comunicar internamente, as redes sociais do LIneA, reuni\u00f5es regulares, gloss\u00e1rio, a pol\u00edtica de seguran\u00e7a da informa\u00e7\u00e3o seguida pelo laborat\u00f3rio, os diferentes tipos de apoio ao usu\u00e1rio disponive\u00eds e, por fim, quem \u00e9 nossa equipe! O manual pode ser acessado por quem desejar entrando nesta p\u00e1gina . Vale dizer que muitas das coisas que est\u00e3o detalhadas no manual de boas vindas voc\u00ea tamb\u00e9m encontra aqui nesta p\u00e1gina de documenta\u00e7\u00e3o, por\u00e9m de forma resumida. Registro de usu\u00e1rios \u00b6 Antes de iniciar seu trabalho e explorar as diversas ferramentas oferecidas pelo LIneA, voc\u00ea precisa fazer o registro na nossa base de usu\u00e1rios. \u00c9 importante que voc\u00ea tenha o conhecimento dos perfis de usu\u00e1rios e entenda em qual deles voc\u00ea melhor se encaixa para fazer o seu registro. Vamos l\u00e1? Perfis para o p\u00fablico \u00b6 Afinal, quem \u00e9 o nosso p\u00fablico? Entendemos que para esse perfil se encaixam os estudantes e pesquisadores em geral, que n\u00e3o fazem parte das colabora\u00e7\u00f5es cient\u00edficas j\u00e1 apoiadas pelo LIneA (veja abaixo). S\u00e3o aqueles que precisam de infraestrutura computacional para desenvolver seus projetos cient\u00edficos e n\u00e3o possuem, em suas institui\u00e7\u00f5es, ferramentas para tal. Pensando nisso, o LIneA oferece gratuitamente m\u00e1quinas e suporte para a comunidade acad\u00eamica. Sendo assim, para proporcionar a melhor experi\u00eancia e atendimento ao usu\u00e1rio, foram criados tr\u00eas tipos de perfis voltados para o p\u00fablico: Bronze - Recomendado para entusiastas da astronomia, estudantes de gradua\u00e7\u00e3o e ensino m\u00e9dio. Com esse perfil voc\u00ea ter\u00e1 acesso ao JupyterHub e aos dados p\u00fablicos do Sloan Digital Sky Survey (SDSS - DR17) e Dark Energy Survey (DES - DR2), com recursos computacionais limitados. Prata - Recomendado para pesquisadores, p\u00f3s-doutorandos e estudantes de p\u00f3s-gradua\u00e7\u00e3o (requer e-mail institucional para o registro). Com esse perfil voc\u00ea ter\u00e1 acesso aos mesmos recursos do perfil bronze, com mais poder computacional e persist\u00eancia de arquivos entre sess\u00f5es. Ouro - \u00c9 indicado para casos/projetos espec\u00edficos e que necessitam de recursos computacionais que v\u00e3o al\u00e9m dos recursos pr\u00e9-definidos para os perfis Bronze e Prata. Se esse \u00e9 o seu caso, voc\u00ea poder\u00e1 submeter um projeto informando a sua necessidade para a aprova\u00e7\u00e3o pelo Comit\u00ea de Usu\u00e1rios do LIneA. Caso ainda n\u00e3o tenha um projeto bem definido, sugerimos que inicie o registro com perfil Prata. Usu\u00e1rios do perfil Prata podem solicitar \" upgrade \" para o perfil ouro a qualquer momento, caso tenham necessidade justificada. Perfis para membros de colabora\u00e7\u00e3o \u00b6 Definimos como membros de colabora\u00e7\u00f5es usu\u00e1rios que s\u00e3o associados a alguma colabora\u00e7\u00e3o cient\u00edfica apoiada pelo LIneA, ou seja, os projetos DESI , DES , LSST , SDSS e TON . Caso voc\u00ea trabalhe diretamente com alguma dessas colabora\u00e7\u00f5es, ent\u00e3o indicamos que esse \u00e9 o seu perfil. Cada colabora\u00e7\u00e3o tem o seu perfil de usu\u00e1rio associado, respeitando as regras de acesso a dados propriet\u00e1rios de cada projeto. Para usu\u00e1rios que participam de mais de uma colabora\u00e7\u00e3o, \u00e9 poss\u00edvel ter um perfil misto e ter acesso a dados de m\u00faltiplos projetos. O v\u00ednculo do usu\u00e1rio com as colabora\u00e7\u00f5es ser\u00e1 verificado pela nossa equipe no processo de aprova\u00e7\u00e3o do registro. Agora que voc\u00ea j\u00e1 sabe qual \u00e9 o seu perfil, o pr\u00f3ximo passo \u00e9 o registro! Como se registrar \u00b6 1 - Acesse o site do LIneA em linea.org.br e clique no menu Servi\u00e7os > Registro . 2 - Ap\u00f3s abrir a p\u00e1gina, escolha o tipo de perfil (Bronze, Prata ou Ouro) ou colabora\u00e7\u00e3o (DESI, DES, LSST, SDSS, e TON) em que voc\u00ea se encaixa. Em seguida, clique em Registre-se via CAFe (Comunidade Acad\u00eamica Federada) ou via Google (apenas para o perfil Bronze). 3 - Voc\u00ea ser\u00e1 redirecionado para efetuar login. Efetue o login com a sua credencial institucional (perfis prata, ouro ou colabora\u00e7\u00f5es) ou Google (perfil bronze), informando o nome de usu\u00e1rio e a senha. Ap\u00f3s efetuar o login, voc\u00ea ser\u00e1 redirecionado de volta para o nosso formul\u00e1rio de registro. 4 - Preencha todos os campos do formul\u00e1rio com suas informa\u00e7\u00f5es. Leia, aceite os termos e clique em \"I Agree\". Para finalizar, clique no bot\u00e3o SUBMIT. 5 - Ap\u00f3s a submiss\u00e3o do formul\u00e1rio a equipe do LIneA ir\u00e1 receber a solicita\u00e7\u00e3o e prosseguir com o provisionamento da sua conta. Aguarde o email de confirma\u00e7\u00e3o . Para maiores informa\u00e7\u00f5es, entre em contato com o Service Desk em helpdesk@linea.org.br .","title":"Primeiros passos"},{"location":"primeiros_passos.html#manual-de-boas-vindas","text":"O manual \u00e9 um compilado de informa\u00e7\u00f5es importantes sobre o LIneA para aqueles que est\u00e3o conhecendo o laborat\u00f3rio pela primeira vez. Nele podemos encontrar a miss\u00e3o, objetivos, as ferramentas para usu\u00e1rios, os servi\u00e7os de e-ci\u00eancias oferecidos, descri\u00e7\u00e3o dos perfis de usu\u00e1rios, onde buscar ajuda, os representantes das colabora\u00e7\u00f5es cient\u00edficas apoiadas pelo LIneA, maneiras de se comunicar internamente, as redes sociais do LIneA, reuni\u00f5es regulares, gloss\u00e1rio, a pol\u00edtica de seguran\u00e7a da informa\u00e7\u00e3o seguida pelo laborat\u00f3rio, os diferentes tipos de apoio ao usu\u00e1rio disponive\u00eds e, por fim, quem \u00e9 nossa equipe! O manual pode ser acessado por quem desejar entrando nesta p\u00e1gina . Vale dizer que muitas das coisas que est\u00e3o detalhadas no manual de boas vindas voc\u00ea tamb\u00e9m encontra aqui nesta p\u00e1gina de documenta\u00e7\u00e3o, por\u00e9m de forma resumida.","title":"Manual de boas-vindas"},{"location":"primeiros_passos.html#registro-de-usuarios","text":"Antes de iniciar seu trabalho e explorar as diversas ferramentas oferecidas pelo LIneA, voc\u00ea precisa fazer o registro na nossa base de usu\u00e1rios. \u00c9 importante que voc\u00ea tenha o conhecimento dos perfis de usu\u00e1rios e entenda em qual deles voc\u00ea melhor se encaixa para fazer o seu registro. Vamos l\u00e1?","title":"Registro de usu\u00e1rios"},{"location":"primeiros_passos.html#perfis-para-o-publico","text":"Afinal, quem \u00e9 o nosso p\u00fablico? Entendemos que para esse perfil se encaixam os estudantes e pesquisadores em geral, que n\u00e3o fazem parte das colabora\u00e7\u00f5es cient\u00edficas j\u00e1 apoiadas pelo LIneA (veja abaixo). S\u00e3o aqueles que precisam de infraestrutura computacional para desenvolver seus projetos cient\u00edficos e n\u00e3o possuem, em suas institui\u00e7\u00f5es, ferramentas para tal. Pensando nisso, o LIneA oferece gratuitamente m\u00e1quinas e suporte para a comunidade acad\u00eamica. Sendo assim, para proporcionar a melhor experi\u00eancia e atendimento ao usu\u00e1rio, foram criados tr\u00eas tipos de perfis voltados para o p\u00fablico: Bronze - Recomendado para entusiastas da astronomia, estudantes de gradua\u00e7\u00e3o e ensino m\u00e9dio. Com esse perfil voc\u00ea ter\u00e1 acesso ao JupyterHub e aos dados p\u00fablicos do Sloan Digital Sky Survey (SDSS - DR17) e Dark Energy Survey (DES - DR2), com recursos computacionais limitados. Prata - Recomendado para pesquisadores, p\u00f3s-doutorandos e estudantes de p\u00f3s-gradua\u00e7\u00e3o (requer e-mail institucional para o registro). Com esse perfil voc\u00ea ter\u00e1 acesso aos mesmos recursos do perfil bronze, com mais poder computacional e persist\u00eancia de arquivos entre sess\u00f5es. Ouro - \u00c9 indicado para casos/projetos espec\u00edficos e que necessitam de recursos computacionais que v\u00e3o al\u00e9m dos recursos pr\u00e9-definidos para os perfis Bronze e Prata. Se esse \u00e9 o seu caso, voc\u00ea poder\u00e1 submeter um projeto informando a sua necessidade para a aprova\u00e7\u00e3o pelo Comit\u00ea de Usu\u00e1rios do LIneA. Caso ainda n\u00e3o tenha um projeto bem definido, sugerimos que inicie o registro com perfil Prata. Usu\u00e1rios do perfil Prata podem solicitar \" upgrade \" para o perfil ouro a qualquer momento, caso tenham necessidade justificada.","title":"Perfis para o p\u00fablico"},{"location":"primeiros_passos.html#perfis-para-membros-de-colaboracao","text":"Definimos como membros de colabora\u00e7\u00f5es usu\u00e1rios que s\u00e3o associados a alguma colabora\u00e7\u00e3o cient\u00edfica apoiada pelo LIneA, ou seja, os projetos DESI , DES , LSST , SDSS e TON . Caso voc\u00ea trabalhe diretamente com alguma dessas colabora\u00e7\u00f5es, ent\u00e3o indicamos que esse \u00e9 o seu perfil. Cada colabora\u00e7\u00e3o tem o seu perfil de usu\u00e1rio associado, respeitando as regras de acesso a dados propriet\u00e1rios de cada projeto. Para usu\u00e1rios que participam de mais de uma colabora\u00e7\u00e3o, \u00e9 poss\u00edvel ter um perfil misto e ter acesso a dados de m\u00faltiplos projetos. O v\u00ednculo do usu\u00e1rio com as colabora\u00e7\u00f5es ser\u00e1 verificado pela nossa equipe no processo de aprova\u00e7\u00e3o do registro. Agora que voc\u00ea j\u00e1 sabe qual \u00e9 o seu perfil, o pr\u00f3ximo passo \u00e9 o registro!","title":"Perfis para membros de colabora\u00e7\u00e3o"},{"location":"primeiros_passos.html#como-se-registrar","text":"1 - Acesse o site do LIneA em linea.org.br e clique no menu Servi\u00e7os > Registro . 2 - Ap\u00f3s abrir a p\u00e1gina, escolha o tipo de perfil (Bronze, Prata ou Ouro) ou colabora\u00e7\u00e3o (DESI, DES, LSST, SDSS, e TON) em que voc\u00ea se encaixa. Em seguida, clique em Registre-se via CAFe (Comunidade Acad\u00eamica Federada) ou via Google (apenas para o perfil Bronze). 3 - Voc\u00ea ser\u00e1 redirecionado para efetuar login. Efetue o login com a sua credencial institucional (perfis prata, ouro ou colabora\u00e7\u00f5es) ou Google (perfil bronze), informando o nome de usu\u00e1rio e a senha. Ap\u00f3s efetuar o login, voc\u00ea ser\u00e1 redirecionado de volta para o nosso formul\u00e1rio de registro. 4 - Preencha todos os campos do formul\u00e1rio com suas informa\u00e7\u00f5es. Leia, aceite os termos e clique em \"I Agree\". Para finalizar, clique no bot\u00e3o SUBMIT. 5 - Ap\u00f3s a submiss\u00e3o do formul\u00e1rio a equipe do LIneA ir\u00e1 receber a solicita\u00e7\u00e3o e prosseguir com o provisionamento da sua conta. Aguarde o email de confirma\u00e7\u00e3o . Para maiores informa\u00e7\u00f5es, entre em contato com o Service Desk em helpdesk@linea.org.br .","title":"Como se registrar"},{"location":"suporte.html","text":"Talvez a sua d\u00favida j\u00e1 tenha resposta, d\u00ea uma olhada na nossa lista de perguntas frequentes antes de abrir um chamado. Para suporte t\u00e9cnico, entre em contato com o nosso Service Desk (suporte via e-mail) ou reserve uma vaga no servi\u00e7o Office Hours (atendimento por v\u00eddeo-chamada) atrav\u00e9s do e-mail helpdesk@linea.org.br . Se voc\u00ea quiser fazer parte da comunidade LIneA e conversar com outros usu\u00e1rios, clique aqui para receber um convite para o Workspace LIneA Users no Slack.","title":"Suporte"},{"location":"armazenamento/index.html","text":"LustreFS (HPC) \u00b6 O ambiente do cluster Apollo conta com sistema de arquivos de alta performance Lustre com dois n\u00edveis ( tiers ) de armazenamento, um em SSD com ~70 TB ( T0 ) e outro em HDD com ~500 TB ( T1 ), ambos conectados a uma rede infiniband EDR de 100 Gb/s. Os dois n\u00edveis de armazenamento est\u00e3o dispon\u00edveis em /lustre/t0 e /lustre/t1 . Os usu\u00e1rios poder\u00e3o acessar seu diret\u00f3rio de scratch atrav\u00e9s da vari\u00e1vel de ambiente $SCRATCH , ou acessando o diret\u00f3rio localizado em /lustre/t0/scratch/users/<username> . Boas pr\u00e1ticas de uso em um sistema Lustre \u00b6 Sistemas de arquivos distribu\u00eddos como o Lustre s\u00e3o ideais para ambientes HPC e HTC. Nesses ambientes, a carga de trabalho t\u00edpica consiste em arquivos grandes que precisam ser acessados \u200b\u200ba partir de muitos n\u00f3s de computa\u00e7\u00e3o com largura de banda muito alta e/ou baixa lat\u00eancia. Portanto, esses sistemas de arquivos s\u00e3o muito diferentes dos sistemas de arquivos usados \u200b\u200bem computadores desktop ou servidores isolados. Embora sejam excelentes no manuseio de arquivos grandes, eles tamb\u00e9m apresentam fortes limita\u00e7\u00f5es ao lidar com arquivos pequenos e padr\u00f5es de acesso mais comumente encontrados em ambientes corporativos e de desktop. As opera\u00e7\u00f5es que podem ser extremamente r\u00e1pidas em um disco local de esta\u00e7\u00e3o de trabalho podem ser dolorosamente lentas e caras em um sistema de arquivos Lustre, afetando tanto os usu\u00e1rios que executam essas opera\u00e7\u00f5es quanto, eventualmente, todos os outros usu\u00e1rios. Estas melhores pr\u00e1ticas e recomenda\u00e7\u00f5es t\u00eam como objetivo permitir um uso tranquilo do Lustre, minimizando ou evitando opera\u00e7\u00f5es desnecess\u00e1rias ou muito caras do sistema de arquivos. Evite acessar atributos de arquivos e diret\u00f3rios Acessar informa\u00e7\u00f5es de metadados, como atributos de arquivo (por exemplo, tipo, propriedade, prote\u00e7\u00e3o, tamanho, datas, etc.) no Lustre consome muitos recursos e pode degradar o desempenho do sistema de arquivos, especialmente quando realizado com frequ\u00eancia ou em diret\u00f3rios com grande quantidade de arquivos. Minimize o uso de chamadas de sistema que acessam ou modificam esses atributos, como stat() , statx() , open() , openat() , etc. O mesmo se aplica a comandos como ls -l ou ls --color que fazem uso das chamadas mencionadas acima. Em vez disso, use um simples ls ou ls -l filename . Evite usar comandos que acessam metadados massivamente \u00b6 Evite usar comandos como ls -R , find , locate , du , df e similares. Esses comandos percorrem o sistema de arquivos recursivamente e/ou executam opera\u00e7\u00f5es pesadas de metadados. Eles s\u00e3o muito intensivos no acesso aos metadados do sistema de arquivos e podem degradar gravemente o desempenho geral do sistema de arquivos. Se for absolutamente necess\u00e1rio percorrer o sistema de arquivos recursivamente, use o comando fornecido com o Lustre lfs find em vez de find , por exemplo. Use o comando Lustre lfs \u00b6 Para minimizar o n\u00famero de chamadas Lustre RPC, sempre que poss\u00edvel use os comandos lfs em vez dos comandos fornecidos pelo sistema: lfs df => em vez de df lfs find => em vez de find Evite usar curingas \u00b6 Expandir os curingas exige muitos recursos. A execu\u00e7\u00e3o de comandos com curingas em um grande n\u00famero de arquivos pode levar muito tempo e afetar gravemente o desempenho do sistema de arquivos. Em vez de usar curingas, crie uma lista dos arquivos de destino e aplique o comando a cada um desses arquivos. Acesso somente leitura \u00b6 Sempre que poss\u00edvel, abra os arquivos como somente leitura usando O_RDONLY , al\u00e9m disso, se voc\u00ea n\u00e3o precisar atualizar o tempo de acesso ao arquivo, abra os arquivos como O_RDONLY | O_NOATIME . Se as informa\u00e7\u00f5es de tempo de acesso forem necess\u00e1rias durante a execu\u00e7\u00e3o de E/S paralela, deixe o processo pai abrir os arquivos como O_RDONLY e todas as outras classifica\u00e7\u00f5es abrirem os mesmos arquivos como O_RDONLY|O_NOATIME . Evite ter um grande n\u00famero de arquivos em um \u00fanico diret\u00f3rio \u00b6 Quando um arquivo \u00e9 acessado, o Lustre bloqueia o diret\u00f3rio pai. Quando muitos arquivos no mesmo diret\u00f3rio devem ser abertos, isso cria conten\u00e7\u00e3o. Gravar milhares de arquivos em um \u00fanico diret\u00f3rio produz uma carga massiva nos servidores de metadados Lustre, geralmente resultando na desativa\u00e7\u00e3o dos sistemas de arquivos. Acessar um \u00fanico diret\u00f3rio contendo milhares de arquivos pode causar grande conten\u00e7\u00e3o de recursos, degradando o desempenho do sistema de arquivos. A alternativa \u00e9 organizar os dados em v\u00e1rios subdiret\u00f3rios e dividir os arquivos entre eles. Uma abordagem comum \u00e9 usar a raiz quadrada do n\u00famero de arquivos, por exemplo, para 90.000 arquivos a raiz quadrada seria 300, portanto devem ser criados 300 diret\u00f3rios contendo 300 arquivos cada. Evite arquivos pequenos \u00b6 Acessar arquivos pequenos no sistema de arquivos Lustre \u00e9 muito ineficiente. O tamanho de arquivo recomendado \u00e9 superior a 1 GB. Reorganize os dados em arquivos grandes ou use formatos de arquivo como HDF5 . Alternativamente, se o tamanho total dos arquivos for pequeno, como alguns gigabytes, copie os arquivos pequenos para /tmp ou para um diret\u00f3rio tempor\u00e1rio local para cada n\u00f3 de computa\u00e7\u00e3o no in\u00edcio do trabalho (n\u00e3o se esque\u00e7a de transferir e/ou excluir os arquivos no fim). Essa abordagem pode ser combinada com o uso de ferramentas de arquivamento, como tar e armazenar pequenos arquivos em um ou mais tarballs grandes podem ser mantidos no Lustre de maneira mais eficiente. Ao ler ou gravar arquivos, o Lustre tem um desempenho muito melhor com tamanhos de buffer grandes (>= 1 MB). \u00c9 altamente recomend\u00e1vel agregar pequenas opera\u00e7\u00f5es de leitura e grava\u00e7\u00e3o em opera\u00e7\u00f5es maiores. O buffer coletivo MPI-IO permite E/S agregada. Evite pequenas opera\u00e7\u00f5es repetitivas de arquivos \u00b6 Evite realizar pequenas opera\u00e7\u00f5es de E/S repetitivas, como abrir arquivos frequentemente no modo de acr\u00e9scimo, gravar pequenas quantidades de dados e fechar o arquivo. Em vez disso, abra o arquivo uma vez, execute todas as opera\u00e7\u00f5es de E/S e feche. Evite v\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo \u00b6 V\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo podem criar conten\u00e7\u00e3o e erros de abertura de arquivos. Em vez disso, execute a abertura a partir de um \u00fanico processo (pai), ou abra o arquivo somente leitura para evitar bloqueio, ou implemente a abertura com uma abordagem de tentativa e erro com suspens\u00e3o em caso de erro. Evite acessar a mesma regi\u00e3o de arquivo de muitos processos Se v\u00e1rios processos acessarem a mesma regi\u00e3o de arquivo ao mesmo tempo, o gerenciador de bloqueio distribu\u00eddo Lustre refor\u00e7ar\u00e1 a coer\u00eancia para que todos os clientes vejam resultados consistentes. Ter muitos processos tentando acessar a mesma regi\u00e3o de arquivo simultaneamente pode causar degrada\u00e7\u00e3o no desempenho. Neste caso, pode ser prefer\u00edvel: replicar o arquivo, dividir o arquivo, executar as opera\u00e7\u00f5es de E/S a partir de uma \u00fanica classifica\u00e7\u00e3o de processo ou garantir que o acesso simult\u00e2neo n\u00e3o ocorrer\u00e1. Em qualquer caso, \u00e9 recomendado manter a quantidade de opera\u00e7\u00f5es de abertura e bloqueio de arquivos em paralelo t\u00e3o pequena quanto poss\u00edvel para reduzir a conten\u00e7\u00e3o. Se v\u00e1rios processos tentarem anexar ao mesmo arquivo, isso acionar\u00e1 o bloqueio e poder\u00e1 causar grande conten\u00e7\u00e3o. Idealmente, apenas um processo deve anexar cada arquivo. Opera\u00e7\u00f5es de arquivo atrav\u00e9s de processo pai \u00b6 Ao acessar pequenos arquivos compartilhados em uma tarefa paralela, muitas vezes \u00e9 mais eficiente executar todas as opera\u00e7\u00f5es necess\u00e1rias atrav\u00e9s do processo pai e, se necess\u00e1rio, transmitir os dados para outras classifica\u00e7\u00f5es, em vez de acessar os mesmos arquivos de todas as classifica\u00e7\u00f5es. Da mesma forma, se m\u00faltiplas classifica\u00e7\u00f5es de um trabalho paralelo requerem informa\u00e7\u00f5es sobre um determinado arquivo, a abordagem mais eficiente \u00e9 fazer com que o processo pai execute as chamadas necess\u00e1rias (por exemplo stat() , fstat() , etc) e ent\u00e3o transmita as informa\u00e7\u00f5es para as outras classifica\u00e7\u00f5es. Distribui\u00e7\u00e3o de arquivos (striping) \u00b6 No Lustre, arquivos grandes podem ser divididos em segmentos que, por sua vez, podem ser distribu\u00eddos automaticamente por v\u00e1rios dispositivos de armazenamento. A distribui\u00e7\u00e3o de arquivos \u00e9 \u00fatil para E/S paralela em arquivos grandes. Para que isso funcione, o ponto de montagem em quest\u00e3o aponta para v\u00e1rios dispositivos de armazenamento (OSTs). O comando lfs df pode ser usado para verificar se um determinado ponto de montagem aponta para v\u00e1rios OSTs. Para obter informa\u00e7\u00f5es de distribui\u00e7\u00e3o de arquivos para um determinado arquivo, use: lfs getstripe filename A distribui\u00e7\u00e3o do arquivo pode ser definida usando o comando lfs setstripe . Se o comando for aplicado a um diret\u00f3rio, ele definir\u00e1 as configura\u00e7\u00f5es de distribui\u00e7\u00e3o padr\u00e3o para arquivos criados nesse diret\u00f3rio. Um subdiret\u00f3rio herda todas as configura\u00e7\u00f5es de distribui\u00e7\u00e3o de seu diret\u00f3rio pai. Se o comando for aplicado a um arquivo, ele distribuir\u00e1 esse arquivo pelos OSTs de acordo com as configura\u00e7\u00f5es especificadas. lfs setstripe -s 128m -c 8 filename => divide o arquivo em segmentos de 128 MB e os distribui em 8 OSTs Se um arquivo grande for compartilhado em paralelo por v\u00e1rios processos, com cada processo trabalhando em sua pr\u00f3pria parte do arquivo, ent\u00e3o pode ser \u00fatil dividir o arquivo em um n\u00famero de segmentos igual ao n\u00famero de processos, ou um m\u00faltiplo do n\u00famero de processos. Para obter o m\u00e1ximo desempenho, as solicita\u00e7\u00f5es de E/S devem ser alinhadas \u00e0s faixas, o que significa que os processos que acessam o arquivo devem faz\u00ea-lo em deslocamentos que correspondam aos limites das faixas. Isto minimiza as chances de um processo ter que acessar mais de um segmento (e mais de um OST) para obter os dados necess\u00e1rios. Para arquivos pequenos, a distribui\u00e7\u00e3o (striping) deve ser desabilitada, isso pode ser conseguido definindo uma contagem de distribui\u00e7\u00e3o de 1. O mesmo se aplica se um arquivo grande for acessado por um \u00fanico processo. lfs setstripe -s 1m -c 1 meudiretorio/arquivospequenos/ Evite instalar software no Lustre \u00b6 Um software geralmente \u00e9 composto de muitos arquivos pequenos e, como mencionado anteriormente, acessar muitos arquivos pequenos no Lustre pode sobrecarregar os servidores de metadados. As compila\u00e7\u00f5es de software em particular podem ser melhor executadas localmente copiando ou descompactando o software para /tmp/$USER/ o para o seu homedir . Al\u00e9m disso, sob alta carga, o acesso de E/S aos sistemas de arquivos Lustre pode ser bloqueado. Se os execut\u00e1veis \u200b\u200bforem armazenados no Lustre e o acesso ao sistema de arquivos falhar, os execut\u00e1veis \u200b\u200bpoder\u00e3o travar. Portanto, sempre que poss\u00edvel, \u00e9 melhor copiar os execut\u00e1veis \u200b\u200bpara o /tmp dos n\u00f3s do cluster. Quota \u00b6 area TB bsoft bhard isoft ihard grace period T0 70 0.4 TB 0.5 TB 10000 11000 7 days \u00c1rea de scratch \u00b6 Os arquivos que n\u00e3o foram modificados nos \u00faltimos 60 dias ser\u00e3o automaticamente removidos. Warning Essa \u00e1rea N\u00c3O sofrer\u00e1 backup e tamb\u00e9m N\u00c3O ser\u00e1 enviado aviso de remo\u00e7\u00e3o de arquivos! Warning O script de limpeza \u00e9 executado uma vez por semana sempre nos fins de semana. Comandos \u00fateis \u00b6 a) Como acessar a minha \u00e1rea de scratch? cd $SCRATCH b) Como consultar a minha quota dispon\u00edvel? lfs quota -u $USER /lustre/t0 c) Como consultar os meus arquivos criados h\u00e1 mais de 60 dias? lfs find $SCRATCH --uid $UID -mtime +60 --print c) Como consultar os meus arquivos criados h\u00e1 menos de 60 dias? lfs find $SCRATCH --uid $UID -mtime -60 --print d) Como listar os OSTs do Lustre? lfs osts /lustre/t0 e) Como listar os arquivos armazenados h\u00e1 mais de 60 dias em um determinado OST do Lustre? lfs find $SCRATCH -mtime +60 --print --obd t0-OST0002_UUID f) Como configurar o striping em diret\u00f3rio de modo a \"quebrar\" os arquivos e distribuir esses \"peda\u00e7os\" em 10 OSTs? lfs setstripe -c 10 $SCRATCH/meus_arquivos_grandes g) Como consultar o striping de arquivos/diret\u00f3rios? lfs setstripe -c $SCRATCH/meus_arquivos_grandes Refer\u00eancias \u00b6 Estas melhores pr\u00e1ticas foram compiladas a partir da experi\u00eancia do time do LIneA e das seguintes fontes: https://www.nas.nasa.gov/hecc/support/kb/lustre-best-practices_226.html https://hpcf.umbc.edu/general-productivity/lustre-best-practices/ https://wiki.gsi.de/foswiki/bin/view/Linux/LustreFs https://doc.lustre.org/lustre_manual.pdf Tip O Lustre do LIneA foi projetado para trabalhar a 100Gbps, para alcan\u00e7ar o m\u00e1ximo de performance fa\u00e7a uso do striping e sempre com arquivos grandes (+1GB). NAS (NFS) \u00b6 Os sistemas de armazenamento NAS s\u00e3o utilizados para armazenamento de longo prazo e n\u00e3o est\u00e3o acess\u00edveis atrav\u00e9s dos n\u00f3s de processamento (HPC). Caracter\u00edsticas atuais: Fabricante Modelo Capacidade Instalado em SGI IS5500 [1] 540TB Dez-2011 SGI IS5600 240TB Jul-2014 [1] este equipamento foi desativado em Jun/2023 devido a problemas f\u00edsicos. /home \u00b6 O diret\u00f3rio home \u00e9 uma \u00e1rea para os usu\u00e1rios armazenarem seus arquivos pessoais e \u00e9 acess\u00edvel atrav\u00e9s dos n\u00f3s de login do cluster e tamb\u00e9m na plataforma jupyter . /archive \u00b6 \u00c1rea de armazenamento de dados brutos de cat\u00e1logos astron\u00f4micos transferidos a partir de outros centros de dados ou produzidos internamente pelas diversas plataformas desenvolvidas pelo LIneA. /process \u00b6 \u00c1rea de armazenamento de dados provenientes do processamento de dados do DES realizados pelo Portal do DES . Quota \u00b6 area bsoft bhard isoft ihard grace period /home 10 GB 15 GB 1000 1100 7 days Backup \u00b6 \u00e1reas frequ\u00eancia tipo reten\u00e7\u00e3o /home di\u00e1rio incremental 90 dias /home mensal completo 90 dias /archive - - - /process - - - /scratch - - -","title":"Armazenamento"},{"location":"armazenamento/index.html#lustrefs-hpc","text":"O ambiente do cluster Apollo conta com sistema de arquivos de alta performance Lustre com dois n\u00edveis ( tiers ) de armazenamento, um em SSD com ~70 TB ( T0 ) e outro em HDD com ~500 TB ( T1 ), ambos conectados a uma rede infiniband EDR de 100 Gb/s. Os dois n\u00edveis de armazenamento est\u00e3o dispon\u00edveis em /lustre/t0 e /lustre/t1 . Os usu\u00e1rios poder\u00e3o acessar seu diret\u00f3rio de scratch atrav\u00e9s da vari\u00e1vel de ambiente $SCRATCH , ou acessando o diret\u00f3rio localizado em /lustre/t0/scratch/users/<username> .","title":"LustreFS (HPC)"},{"location":"armazenamento/index.html#boas-praticas-de-uso-em-um-sistema-lustre","text":"Sistemas de arquivos distribu\u00eddos como o Lustre s\u00e3o ideais para ambientes HPC e HTC. Nesses ambientes, a carga de trabalho t\u00edpica consiste em arquivos grandes que precisam ser acessados \u200b\u200ba partir de muitos n\u00f3s de computa\u00e7\u00e3o com largura de banda muito alta e/ou baixa lat\u00eancia. Portanto, esses sistemas de arquivos s\u00e3o muito diferentes dos sistemas de arquivos usados \u200b\u200bem computadores desktop ou servidores isolados. Embora sejam excelentes no manuseio de arquivos grandes, eles tamb\u00e9m apresentam fortes limita\u00e7\u00f5es ao lidar com arquivos pequenos e padr\u00f5es de acesso mais comumente encontrados em ambientes corporativos e de desktop. As opera\u00e7\u00f5es que podem ser extremamente r\u00e1pidas em um disco local de esta\u00e7\u00e3o de trabalho podem ser dolorosamente lentas e caras em um sistema de arquivos Lustre, afetando tanto os usu\u00e1rios que executam essas opera\u00e7\u00f5es quanto, eventualmente, todos os outros usu\u00e1rios. Estas melhores pr\u00e1ticas e recomenda\u00e7\u00f5es t\u00eam como objetivo permitir um uso tranquilo do Lustre, minimizando ou evitando opera\u00e7\u00f5es desnecess\u00e1rias ou muito caras do sistema de arquivos. Evite acessar atributos de arquivos e diret\u00f3rios Acessar informa\u00e7\u00f5es de metadados, como atributos de arquivo (por exemplo, tipo, propriedade, prote\u00e7\u00e3o, tamanho, datas, etc.) no Lustre consome muitos recursos e pode degradar o desempenho do sistema de arquivos, especialmente quando realizado com frequ\u00eancia ou em diret\u00f3rios com grande quantidade de arquivos. Minimize o uso de chamadas de sistema que acessam ou modificam esses atributos, como stat() , statx() , open() , openat() , etc. O mesmo se aplica a comandos como ls -l ou ls --color que fazem uso das chamadas mencionadas acima. Em vez disso, use um simples ls ou ls -l filename .","title":"Boas pr\u00e1ticas de uso em um sistema Lustre"},{"location":"armazenamento/index.html#evite-usar-comandos-que-acessam-metadados-massivamente","text":"Evite usar comandos como ls -R , find , locate , du , df e similares. Esses comandos percorrem o sistema de arquivos recursivamente e/ou executam opera\u00e7\u00f5es pesadas de metadados. Eles s\u00e3o muito intensivos no acesso aos metadados do sistema de arquivos e podem degradar gravemente o desempenho geral do sistema de arquivos. Se for absolutamente necess\u00e1rio percorrer o sistema de arquivos recursivamente, use o comando fornecido com o Lustre lfs find em vez de find , por exemplo.","title":"Evite usar comandos que acessam metadados massivamente"},{"location":"armazenamento/index.html#use-o-comando-lustre-lfs","text":"Para minimizar o n\u00famero de chamadas Lustre RPC, sempre que poss\u00edvel use os comandos lfs em vez dos comandos fornecidos pelo sistema: lfs df => em vez de df lfs find => em vez de find","title":"Use o comando Lustre lfs"},{"location":"armazenamento/index.html#evite-usar-curingas","text":"Expandir os curingas exige muitos recursos. A execu\u00e7\u00e3o de comandos com curingas em um grande n\u00famero de arquivos pode levar muito tempo e afetar gravemente o desempenho do sistema de arquivos. Em vez de usar curingas, crie uma lista dos arquivos de destino e aplique o comando a cada um desses arquivos.","title":"Evite usar curingas"},{"location":"armazenamento/index.html#acesso-somente-leitura","text":"Sempre que poss\u00edvel, abra os arquivos como somente leitura usando O_RDONLY , al\u00e9m disso, se voc\u00ea n\u00e3o precisar atualizar o tempo de acesso ao arquivo, abra os arquivos como O_RDONLY | O_NOATIME . Se as informa\u00e7\u00f5es de tempo de acesso forem necess\u00e1rias durante a execu\u00e7\u00e3o de E/S paralela, deixe o processo pai abrir os arquivos como O_RDONLY e todas as outras classifica\u00e7\u00f5es abrirem os mesmos arquivos como O_RDONLY|O_NOATIME .","title":"Acesso somente leitura"},{"location":"armazenamento/index.html#evite-ter-um-grande-numero-de-arquivos-em-um-unico-diretorio","text":"Quando um arquivo \u00e9 acessado, o Lustre bloqueia o diret\u00f3rio pai. Quando muitos arquivos no mesmo diret\u00f3rio devem ser abertos, isso cria conten\u00e7\u00e3o. Gravar milhares de arquivos em um \u00fanico diret\u00f3rio produz uma carga massiva nos servidores de metadados Lustre, geralmente resultando na desativa\u00e7\u00e3o dos sistemas de arquivos. Acessar um \u00fanico diret\u00f3rio contendo milhares de arquivos pode causar grande conten\u00e7\u00e3o de recursos, degradando o desempenho do sistema de arquivos. A alternativa \u00e9 organizar os dados em v\u00e1rios subdiret\u00f3rios e dividir os arquivos entre eles. Uma abordagem comum \u00e9 usar a raiz quadrada do n\u00famero de arquivos, por exemplo, para 90.000 arquivos a raiz quadrada seria 300, portanto devem ser criados 300 diret\u00f3rios contendo 300 arquivos cada.","title":"Evite ter um grande n\u00famero de arquivos em um \u00fanico diret\u00f3rio"},{"location":"armazenamento/index.html#evite-arquivos-pequenos","text":"Acessar arquivos pequenos no sistema de arquivos Lustre \u00e9 muito ineficiente. O tamanho de arquivo recomendado \u00e9 superior a 1 GB. Reorganize os dados em arquivos grandes ou use formatos de arquivo como HDF5 . Alternativamente, se o tamanho total dos arquivos for pequeno, como alguns gigabytes, copie os arquivos pequenos para /tmp ou para um diret\u00f3rio tempor\u00e1rio local para cada n\u00f3 de computa\u00e7\u00e3o no in\u00edcio do trabalho (n\u00e3o se esque\u00e7a de transferir e/ou excluir os arquivos no fim). Essa abordagem pode ser combinada com o uso de ferramentas de arquivamento, como tar e armazenar pequenos arquivos em um ou mais tarballs grandes podem ser mantidos no Lustre de maneira mais eficiente. Ao ler ou gravar arquivos, o Lustre tem um desempenho muito melhor com tamanhos de buffer grandes (>= 1 MB). \u00c9 altamente recomend\u00e1vel agregar pequenas opera\u00e7\u00f5es de leitura e grava\u00e7\u00e3o em opera\u00e7\u00f5es maiores. O buffer coletivo MPI-IO permite E/S agregada.","title":"Evite arquivos pequenos"},{"location":"armazenamento/index.html#evite-pequenas-operacoes-repetitivas-de-arquivos","text":"Evite realizar pequenas opera\u00e7\u00f5es de E/S repetitivas, como abrir arquivos frequentemente no modo de acr\u00e9scimo, gravar pequenas quantidades de dados e fechar o arquivo. Em vez disso, abra o arquivo uma vez, execute todas as opera\u00e7\u00f5es de E/S e feche.","title":"Evite pequenas opera\u00e7\u00f5es repetitivas de arquivos"},{"location":"armazenamento/index.html#evite-varios-processos-abrindo-os-mesmos-arquivos-ao-mesmo-tempo","text":"V\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo podem criar conten\u00e7\u00e3o e erros de abertura de arquivos. Em vez disso, execute a abertura a partir de um \u00fanico processo (pai), ou abra o arquivo somente leitura para evitar bloqueio, ou implemente a abertura com uma abordagem de tentativa e erro com suspens\u00e3o em caso de erro. Evite acessar a mesma regi\u00e3o de arquivo de muitos processos Se v\u00e1rios processos acessarem a mesma regi\u00e3o de arquivo ao mesmo tempo, o gerenciador de bloqueio distribu\u00eddo Lustre refor\u00e7ar\u00e1 a coer\u00eancia para que todos os clientes vejam resultados consistentes. Ter muitos processos tentando acessar a mesma regi\u00e3o de arquivo simultaneamente pode causar degrada\u00e7\u00e3o no desempenho. Neste caso, pode ser prefer\u00edvel: replicar o arquivo, dividir o arquivo, executar as opera\u00e7\u00f5es de E/S a partir de uma \u00fanica classifica\u00e7\u00e3o de processo ou garantir que o acesso simult\u00e2neo n\u00e3o ocorrer\u00e1. Em qualquer caso, \u00e9 recomendado manter a quantidade de opera\u00e7\u00f5es de abertura e bloqueio de arquivos em paralelo t\u00e3o pequena quanto poss\u00edvel para reduzir a conten\u00e7\u00e3o. Se v\u00e1rios processos tentarem anexar ao mesmo arquivo, isso acionar\u00e1 o bloqueio e poder\u00e1 causar grande conten\u00e7\u00e3o. Idealmente, apenas um processo deve anexar cada arquivo.","title":"Evite v\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo"},{"location":"armazenamento/index.html#operacoes-de-arquivo-atraves-de-processo-pai","text":"Ao acessar pequenos arquivos compartilhados em uma tarefa paralela, muitas vezes \u00e9 mais eficiente executar todas as opera\u00e7\u00f5es necess\u00e1rias atrav\u00e9s do processo pai e, se necess\u00e1rio, transmitir os dados para outras classifica\u00e7\u00f5es, em vez de acessar os mesmos arquivos de todas as classifica\u00e7\u00f5es. Da mesma forma, se m\u00faltiplas classifica\u00e7\u00f5es de um trabalho paralelo requerem informa\u00e7\u00f5es sobre um determinado arquivo, a abordagem mais eficiente \u00e9 fazer com que o processo pai execute as chamadas necess\u00e1rias (por exemplo stat() , fstat() , etc) e ent\u00e3o transmita as informa\u00e7\u00f5es para as outras classifica\u00e7\u00f5es.","title":"Opera\u00e7\u00f5es de arquivo atrav\u00e9s de processo pai"},{"location":"armazenamento/index.html#distribuicao-de-arquivos-striping","text":"No Lustre, arquivos grandes podem ser divididos em segmentos que, por sua vez, podem ser distribu\u00eddos automaticamente por v\u00e1rios dispositivos de armazenamento. A distribui\u00e7\u00e3o de arquivos \u00e9 \u00fatil para E/S paralela em arquivos grandes. Para que isso funcione, o ponto de montagem em quest\u00e3o aponta para v\u00e1rios dispositivos de armazenamento (OSTs). O comando lfs df pode ser usado para verificar se um determinado ponto de montagem aponta para v\u00e1rios OSTs. Para obter informa\u00e7\u00f5es de distribui\u00e7\u00e3o de arquivos para um determinado arquivo, use: lfs getstripe filename A distribui\u00e7\u00e3o do arquivo pode ser definida usando o comando lfs setstripe . Se o comando for aplicado a um diret\u00f3rio, ele definir\u00e1 as configura\u00e7\u00f5es de distribui\u00e7\u00e3o padr\u00e3o para arquivos criados nesse diret\u00f3rio. Um subdiret\u00f3rio herda todas as configura\u00e7\u00f5es de distribui\u00e7\u00e3o de seu diret\u00f3rio pai. Se o comando for aplicado a um arquivo, ele distribuir\u00e1 esse arquivo pelos OSTs de acordo com as configura\u00e7\u00f5es especificadas. lfs setstripe -s 128m -c 8 filename => divide o arquivo em segmentos de 128 MB e os distribui em 8 OSTs Se um arquivo grande for compartilhado em paralelo por v\u00e1rios processos, com cada processo trabalhando em sua pr\u00f3pria parte do arquivo, ent\u00e3o pode ser \u00fatil dividir o arquivo em um n\u00famero de segmentos igual ao n\u00famero de processos, ou um m\u00faltiplo do n\u00famero de processos. Para obter o m\u00e1ximo desempenho, as solicita\u00e7\u00f5es de E/S devem ser alinhadas \u00e0s faixas, o que significa que os processos que acessam o arquivo devem faz\u00ea-lo em deslocamentos que correspondam aos limites das faixas. Isto minimiza as chances de um processo ter que acessar mais de um segmento (e mais de um OST) para obter os dados necess\u00e1rios. Para arquivos pequenos, a distribui\u00e7\u00e3o (striping) deve ser desabilitada, isso pode ser conseguido definindo uma contagem de distribui\u00e7\u00e3o de 1. O mesmo se aplica se um arquivo grande for acessado por um \u00fanico processo. lfs setstripe -s 1m -c 1 meudiretorio/arquivospequenos/","title":"Distribui\u00e7\u00e3o de arquivos (striping)"},{"location":"armazenamento/index.html#evite-instalar-software-no-lustre","text":"Um software geralmente \u00e9 composto de muitos arquivos pequenos e, como mencionado anteriormente, acessar muitos arquivos pequenos no Lustre pode sobrecarregar os servidores de metadados. As compila\u00e7\u00f5es de software em particular podem ser melhor executadas localmente copiando ou descompactando o software para /tmp/$USER/ o para o seu homedir . Al\u00e9m disso, sob alta carga, o acesso de E/S aos sistemas de arquivos Lustre pode ser bloqueado. Se os execut\u00e1veis \u200b\u200bforem armazenados no Lustre e o acesso ao sistema de arquivos falhar, os execut\u00e1veis \u200b\u200bpoder\u00e3o travar. Portanto, sempre que poss\u00edvel, \u00e9 melhor copiar os execut\u00e1veis \u200b\u200bpara o /tmp dos n\u00f3s do cluster.","title":"Evite instalar software no Lustre"},{"location":"armazenamento/index.html#quota","text":"area TB bsoft bhard isoft ihard grace period T0 70 0.4 TB 0.5 TB 10000 11000 7 days","title":"Quota"},{"location":"armazenamento/index.html#area-de-scratch","text":"Os arquivos que n\u00e3o foram modificados nos \u00faltimos 60 dias ser\u00e3o automaticamente removidos. Warning Essa \u00e1rea N\u00c3O sofrer\u00e1 backup e tamb\u00e9m N\u00c3O ser\u00e1 enviado aviso de remo\u00e7\u00e3o de arquivos! Warning O script de limpeza \u00e9 executado uma vez por semana sempre nos fins de semana.","title":"\u00c1rea de scratch"},{"location":"armazenamento/index.html#comandos-uteis","text":"a) Como acessar a minha \u00e1rea de scratch? cd $SCRATCH b) Como consultar a minha quota dispon\u00edvel? lfs quota -u $USER /lustre/t0 c) Como consultar os meus arquivos criados h\u00e1 mais de 60 dias? lfs find $SCRATCH --uid $UID -mtime +60 --print c) Como consultar os meus arquivos criados h\u00e1 menos de 60 dias? lfs find $SCRATCH --uid $UID -mtime -60 --print d) Como listar os OSTs do Lustre? lfs osts /lustre/t0 e) Como listar os arquivos armazenados h\u00e1 mais de 60 dias em um determinado OST do Lustre? lfs find $SCRATCH -mtime +60 --print --obd t0-OST0002_UUID f) Como configurar o striping em diret\u00f3rio de modo a \"quebrar\" os arquivos e distribuir esses \"peda\u00e7os\" em 10 OSTs? lfs setstripe -c 10 $SCRATCH/meus_arquivos_grandes g) Como consultar o striping de arquivos/diret\u00f3rios? lfs setstripe -c $SCRATCH/meus_arquivos_grandes","title":"Comandos \u00fateis"},{"location":"armazenamento/index.html#referencias","text":"Estas melhores pr\u00e1ticas foram compiladas a partir da experi\u00eancia do time do LIneA e das seguintes fontes: https://www.nas.nasa.gov/hecc/support/kb/lustre-best-practices_226.html https://hpcf.umbc.edu/general-productivity/lustre-best-practices/ https://wiki.gsi.de/foswiki/bin/view/Linux/LustreFs https://doc.lustre.org/lustre_manual.pdf Tip O Lustre do LIneA foi projetado para trabalhar a 100Gbps, para alcan\u00e7ar o m\u00e1ximo de performance fa\u00e7a uso do striping e sempre com arquivos grandes (+1GB).","title":"Refer\u00eancias"},{"location":"armazenamento/index.html#nas-nfs","text":"Os sistemas de armazenamento NAS s\u00e3o utilizados para armazenamento de longo prazo e n\u00e3o est\u00e3o acess\u00edveis atrav\u00e9s dos n\u00f3s de processamento (HPC). Caracter\u00edsticas atuais: Fabricante Modelo Capacidade Instalado em SGI IS5500 [1] 540TB Dez-2011 SGI IS5600 240TB Jul-2014 [1] este equipamento foi desativado em Jun/2023 devido a problemas f\u00edsicos.","title":"NAS (NFS)"},{"location":"armazenamento/index.html#home","text":"O diret\u00f3rio home \u00e9 uma \u00e1rea para os usu\u00e1rios armazenarem seus arquivos pessoais e \u00e9 acess\u00edvel atrav\u00e9s dos n\u00f3s de login do cluster e tamb\u00e9m na plataforma jupyter .","title":"/home"},{"location":"armazenamento/index.html#archive","text":"\u00c1rea de armazenamento de dados brutos de cat\u00e1logos astron\u00f4micos transferidos a partir de outros centros de dados ou produzidos internamente pelas diversas plataformas desenvolvidas pelo LIneA.","title":"/archive"},{"location":"armazenamento/index.html#process","text":"\u00c1rea de armazenamento de dados provenientes do processamento de dados do DES realizados pelo Portal do DES .","title":"/process"},{"location":"armazenamento/index.html#quota_1","text":"area bsoft bhard isoft ihard grace period /home 10 GB 15 GB 1000 1100 7 days","title":"Quota"},{"location":"armazenamento/index.html#backup","text":"\u00e1reas frequ\u00eancia tipo reten\u00e7\u00e3o /home di\u00e1rio incremental 90 dias /home mensal completo 90 dias /archive - - - /process - - - /scratch - - -","title":"Backup"},{"location":"armazenamento/lustre.html","text":"","title":"Lustre"},{"location":"armazenamento/lustrefs.html","text":"","title":"Lustrefs"},{"location":"data/index.html","text":"Acervo de Dados \u00b6 Warning Em breve.","title":"Dados"},{"location":"data/index.html#acervo-de-dados","text":"Warning Em breve.","title":"Acervo de Dados"},{"location":"data/des.html","text":"DES \u00b6 Warning Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda DES datasets available at LIneA Levantamento inicial de informa\u00e7\u00f5es sobre os datasets do DES dispon\u00edveis no ambiente Archive \u00b6 DR2 \u00b6 There is no DR2 on Archive Paper or reference: https://ui.adsabs.harvard.edu/abs/2021ApJS..255...20A/abstract Description (paper's abstract): We present the second public data release of the Dark Energy Survey, DES DR2, based on optical/near-infrared imaging by the Dark Energy Camera mounted on the 4 m Blanco telescope at Cerro Tololo Inter-American Observatory in Chile. DES DR2 consists of reduced single-epoch and coadded images, a source catalog derived from coadded images, and associated data products assembled from 6 yr of DES science operations. This release includes data from the DES wide-area survey covering ~5000 deg2 of the southern Galactic cap in five broad photometric bands, grizY. DES DR2 has a median delivered point-spread function FWHM of g = 1.11 arcsec, r = 0.95 arcsec, i = 0.88 arcsec, z = 0.83 arcsec, and Y = 0.90 arcsec, photometric uniformity with a standard deviation of <3 mmag with respect to Gaia DR2 G band, a photometric accuracy of ~11 mmag, and a median internal astrometric precision of ~27 mas. The median coadded catalog depth for a 1.95 arcsec diameter aperture at signal-to-noise ratio = 10 is g = 24.7, r = 24.4, i = 23.8, z = 23.1, and Y = 21.7 mag. DES DR2 includes ~691 million distinct astronomical objects detected in 10,169 coadded image tiles of size 0.534 deg2 produced from 76,217 single-epoch images. After a basic quality selection, benchmark galaxy and stellar samples contain 543 million and 145 million objects, respectively. These data are accessible through several interfaces, including interactive image visualization tools, web-based query clients, image cutout servers, and Jupyter notebooks. DES DR2 constitutes the largest photometric data set to date at the achieved depth and photometric precision. Data access (catalogs and images): easyaccess (internal collaboration) https://desportal.cosmology.illinois.edu/ (internal collaboration) https://des.ncsa.illinois.edu/desaccess/ (public) https://desportal2.cosmology.illinois.edu/ (public) https://datalab.noirlab.edu (public) Y6A1_COADD and Y6A1_GOLD (and SMALL versions) \u00b6 tree -L 2 Y6A1_COADD/ Y6A1_COADD/ \u251c\u2500\u2500 Y6A1_COADD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 depth_maps \u2502 \u2514\u2500\u2500 masks \u251c\u2500\u2500 Y6A1_COADD_SMALL \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 masks \u2502 \u2514\u2500\u2500 masks_ -> ../Y6A1_COADD/masks \u251c\u2500\u2500 Y6A1_GOLD \u2502 \u251c\u2500\u2500 cats \u2502 \u2514\u2500\u2500 masks \u2514\u2500\u2500 Y6A1_GOLD_SMALL \u251c\u2500\u2500 healpix \u2514\u2500\u2500 masks 14 directories, 0 files du -khs Y6A1_COADD/*/* 3.6T Y6A1_COADD/Y6A1_COADD/cats 2.4G Y6A1_COADD/Y6A1_COADD/depth_maps 1.2T Y6A1_COADD/Y6A1_COADD/masks 46G Y6A1_COADD/Y6A1_COADD_SMALL/healpix 16K Y6A1_COADD/Y6A1_COADD_SMALL/masks 0 Y6A1_COADD/Y6A1_COADD_SMALL/masks_ 2.3T Y6A1_COADD/Y6A1_GOLD/cats 368K Y6A1_COADD/Y6A1_GOLD/masks 3.0G Y6A1_COADD/Y6A1_GOLD_SMALL/healpix 4.0K Y6A1_COADD/Y6A1_GOLD_SMALL/masks - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&title=Y6A1+Release+Notes https://cdcvs.fnal.gov/redmine/projects/des-y6/wiki/Y6_Gold_release - Description: This is not a public catalog, only available for the collaboration. Y6A1 is the first version of DES-Y6 coadd catalog and image, covering all five bands. Y6A1_COADD here is the table Y6A1_COADD_OBJECT_SUMMARY available for the collaboration (also available on easyaccess), and the catalog here is the full catalog for Y6A1 coadd, with 186 columns and 691498505 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a version of Y6A1_GOLD catalog, which is a catalog based on Y6A1_COADD, but with a few measurements added. The catalog here has 125 columns of the version Y6_GOLD_1_1 (in easyaccess the versions available are Y6_GOLD_1_1, Y6_GOLD_2_0, and Y6_GOLD_2_1), with 334 columns. The catalog Y6_GOLD_1_1 in easyaccess has 690153156 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a minimal documentation about the depth maps (where they came from, etc). The masks are the complete list of files (*.pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps. Files are organized per tile and band (101689 tiles and five bands). - Data access (catalogs and images): easyaccess (internal collaboration) Y6A2_COADD, Y6A2_GOLD, Y6A2_SOF (and SMALL versions) \u00b6 tree -L 2 Y6A2_COADD/ Y6A2_COADD/ \u251c\u2500\u2500 masks \u251c\u2500\u2500 Y6A2_COADD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 cats_y6a2 \u2502 \u251c\u2500\u2500 fits \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 maps \u2502 \u251c\u2500\u2500 masks \u2502 \u251c\u2500\u2500 pngs \u2502 \u2514\u2500\u2500 stilts_converter_Y6A2-coadd_to_Y6A2-small.sh \u251c\u2500\u2500 Y6A2_COADD_SMALL \u2502 \u2514\u2500\u2500 healpix \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 install \u2502 \u251c\u2500\u2500 Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits \u2502 \u2514\u2500\u2500 Y6_Gold_2_0.csv \u251c\u2500\u2500 Y6A2_GOLD_SMALL \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 healpix \u2502 \u2514\u2500\u2500 install \u251c\u2500\u2500 Y6A2_SOF_V2 \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 install \u2502 \u2514\u2500\u2500 Y6A2_SOF_V2.csv \u2514\u2500\u2500 Y6_Gold_2_0 \u2514\u2500\u2500 Y6_Gold_2_0 du -khs Y6A2_COADD/*/* 274M Y6A2_COADD/Y6A2_COADD/cats 0 Y6A2_COADD/Y6A2_COADD/cats_y6a2 0 Y6A2_COADD/Y6A2_COADD/fits 898G Y6A2_COADD/Y6A2_COADD/healpix 0 Y6A2_COADD/Y6A2_COADD/maps 9.1G Y6A2_COADD/Y6A2_COADD/masks 0 Y6A2_COADD/Y6A2_COADD/pngs 4.0K Y6A2_COADD/Y6A2_COADD_SMALL/healpix 4.0K Y6A2_COADD/Y6A2_COADD/stilts_converter_Y6A2-coadd_to_Y6A2-small.sh 1.7T Y6A2_COADD/Y6A2_GOLD/cats 36K Y6A2_COADD/Y6A2_GOLD/install 0 Y6A2_COADD/Y6A2_GOLD_SMALL/cats 3.2G Y6A2_COADD/Y6A2_GOLD_SMALL/healpix 196K Y6A2_COADD/Y6A2_GOLD_SMALL/install 15G Y6A2_COADD/Y6A2_GOLD/Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits 132K Y6A2_COADD/Y6A2_GOLD/Y6_Gold_2_0.csv 904G Y6A2_COADD/Y6A2_SOF_V2/cats 0 Y6A2_COADD/Y6A2_SOF_V2/healpix 14M Y6A2_COADD/Y6A2_SOF_V2/install 132K Y6A2_COADD/Y6A2_SOF_V2/Y6A2_SOF_V2.csv 0 Y6A2_COADD/Y6_Gold_2_0/Y6_Gold_2_0 - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&title=Y6A1+Release+Notes - Description: This is not a public catalog, only available for the collaboration. Y6A2 is the reprocessing of only 73 tiles after detect an issue in align DECam images (see the Y6A1 description for reference). See the list of tiles in https://desar2.cosmology.illinois.edu/DESFiles/desarchive/OPS/multiepoch/Y6A2/r5137/ . Files in Y6A2_COADD/Y6A2_COADD/healpix/32/ .fits here is the table Y6A2_COADD_OBJECT_SUMMARY available for the collaboration, with 186 columns and 691483608 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. The masks are the set list of files ( .pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps for only the tiles that changed in Y6A1 to Y6A2. Y6A2_GOLD is the catalog Y6_GOLD_2_0 version available on easyaccess. The files are split by tile in folder Y6A2_GOLD/cats. The files copied here have the same amount of 333 columns and 691483608 objects. Data access (catalogs and images): easyaccess (internal collaboration) T1 tree -L 2 . . \u251c\u2500\u2500 desar2.cosmology.illinois.edu \u2502 \u2514\u2500\u2500 DESFiles \u251c\u2500\u2500 dr2 \u2502 \u251c\u2500\u2500 fits \u2502 \u2514\u2500\u2500 ptifs \u251c\u2500\u2500 images \u2502 \u2514\u2500\u2500 y6a1_hips \u251c\u2500\u2500 process \u2502 \u251c\u2500\u2500 production \u2502 \u251c\u2500\u2500 testing \u2502 \u2514\u2500\u2500 testnagios \u251c\u2500\u2500 Y6A2_COADD \u2502 \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u2514\u2500\u2500 Y6A2_GOLD_SMALL \u251c\u2500\u2500 y6a2_gold \u2502 \u2514\u2500\u2500 cats \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u2514\u2500\u2500 cats \u251c\u2500\u2500 Y6A2_GOLD_FITS \u2502 \u2514\u2500\u2500 BALANCED \u2514\u2500\u2500 Y6_SUBSET_HIPS \u251c\u2500\u2500 AladinBeta.jar \u251c\u2500\u2500 Hipsgen-cat.jar \u251c\u2500\u2500 imagens \u2514\u2500\u2500 outputs 23 directories, 2 files Getting information about datasets volume size","title":"DES"},{"location":"data/des.html#des","text":"Warning Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda DES datasets available at LIneA Levantamento inicial de informa\u00e7\u00f5es sobre os datasets do DES dispon\u00edveis no ambiente","title":"DES"},{"location":"data/des.html#archive","text":"","title":"Archive"},{"location":"data/des.html#dr2","text":"There is no DR2 on Archive Paper or reference: https://ui.adsabs.harvard.edu/abs/2021ApJS..255...20A/abstract Description (paper's abstract): We present the second public data release of the Dark Energy Survey, DES DR2, based on optical/near-infrared imaging by the Dark Energy Camera mounted on the 4 m Blanco telescope at Cerro Tololo Inter-American Observatory in Chile. DES DR2 consists of reduced single-epoch and coadded images, a source catalog derived from coadded images, and associated data products assembled from 6 yr of DES science operations. This release includes data from the DES wide-area survey covering ~5000 deg2 of the southern Galactic cap in five broad photometric bands, grizY. DES DR2 has a median delivered point-spread function FWHM of g = 1.11 arcsec, r = 0.95 arcsec, i = 0.88 arcsec, z = 0.83 arcsec, and Y = 0.90 arcsec, photometric uniformity with a standard deviation of <3 mmag with respect to Gaia DR2 G band, a photometric accuracy of ~11 mmag, and a median internal astrometric precision of ~27 mas. The median coadded catalog depth for a 1.95 arcsec diameter aperture at signal-to-noise ratio = 10 is g = 24.7, r = 24.4, i = 23.8, z = 23.1, and Y = 21.7 mag. DES DR2 includes ~691 million distinct astronomical objects detected in 10,169 coadded image tiles of size 0.534 deg2 produced from 76,217 single-epoch images. After a basic quality selection, benchmark galaxy and stellar samples contain 543 million and 145 million objects, respectively. These data are accessible through several interfaces, including interactive image visualization tools, web-based query clients, image cutout servers, and Jupyter notebooks. DES DR2 constitutes the largest photometric data set to date at the achieved depth and photometric precision. Data access (catalogs and images): easyaccess (internal collaboration) https://desportal.cosmology.illinois.edu/ (internal collaboration) https://des.ncsa.illinois.edu/desaccess/ (public) https://desportal2.cosmology.illinois.edu/ (public) https://datalab.noirlab.edu (public)","title":"DR2"},{"location":"data/des.html#y6a1_coadd-and-y6a1_gold-and-small-versions","text":"tree -L 2 Y6A1_COADD/ Y6A1_COADD/ \u251c\u2500\u2500 Y6A1_COADD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 depth_maps \u2502 \u2514\u2500\u2500 masks \u251c\u2500\u2500 Y6A1_COADD_SMALL \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 masks \u2502 \u2514\u2500\u2500 masks_ -> ../Y6A1_COADD/masks \u251c\u2500\u2500 Y6A1_GOLD \u2502 \u251c\u2500\u2500 cats \u2502 \u2514\u2500\u2500 masks \u2514\u2500\u2500 Y6A1_GOLD_SMALL \u251c\u2500\u2500 healpix \u2514\u2500\u2500 masks 14 directories, 0 files du -khs Y6A1_COADD/*/* 3.6T Y6A1_COADD/Y6A1_COADD/cats 2.4G Y6A1_COADD/Y6A1_COADD/depth_maps 1.2T Y6A1_COADD/Y6A1_COADD/masks 46G Y6A1_COADD/Y6A1_COADD_SMALL/healpix 16K Y6A1_COADD/Y6A1_COADD_SMALL/masks 0 Y6A1_COADD/Y6A1_COADD_SMALL/masks_ 2.3T Y6A1_COADD/Y6A1_GOLD/cats 368K Y6A1_COADD/Y6A1_GOLD/masks 3.0G Y6A1_COADD/Y6A1_GOLD_SMALL/healpix 4.0K Y6A1_COADD/Y6A1_GOLD_SMALL/masks - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&title=Y6A1+Release+Notes https://cdcvs.fnal.gov/redmine/projects/des-y6/wiki/Y6_Gold_release - Description: This is not a public catalog, only available for the collaboration. Y6A1 is the first version of DES-Y6 coadd catalog and image, covering all five bands. Y6A1_COADD here is the table Y6A1_COADD_OBJECT_SUMMARY available for the collaboration (also available on easyaccess), and the catalog here is the full catalog for Y6A1 coadd, with 186 columns and 691498505 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a version of Y6A1_GOLD catalog, which is a catalog based on Y6A1_COADD, but with a few measurements added. The catalog here has 125 columns of the version Y6_GOLD_1_1 (in easyaccess the versions available are Y6_GOLD_1_1, Y6_GOLD_2_0, and Y6_GOLD_2_1), with 334 columns. The catalog Y6_GOLD_1_1 in easyaccess has 690153156 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a minimal documentation about the depth maps (where they came from, etc). The masks are the complete list of files (*.pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps. Files are organized per tile and band (101689 tiles and five bands). - Data access (catalogs and images): easyaccess (internal collaboration)","title":"Y6A1_COADD and Y6A1_GOLD (and SMALL versions)"},{"location":"data/des.html#y6a2_coadd-y6a2_gold-y6a2_sof-and-small-versions","text":"tree -L 2 Y6A2_COADD/ Y6A2_COADD/ \u251c\u2500\u2500 masks \u251c\u2500\u2500 Y6A2_COADD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 cats_y6a2 \u2502 \u251c\u2500\u2500 fits \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 maps \u2502 \u251c\u2500\u2500 masks \u2502 \u251c\u2500\u2500 pngs \u2502 \u2514\u2500\u2500 stilts_converter_Y6A2-coadd_to_Y6A2-small.sh \u251c\u2500\u2500 Y6A2_COADD_SMALL \u2502 \u2514\u2500\u2500 healpix \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 install \u2502 \u251c\u2500\u2500 Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits \u2502 \u2514\u2500\u2500 Y6_Gold_2_0.csv \u251c\u2500\u2500 Y6A2_GOLD_SMALL \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 healpix \u2502 \u2514\u2500\u2500 install \u251c\u2500\u2500 Y6A2_SOF_V2 \u2502 \u251c\u2500\u2500 cats \u2502 \u251c\u2500\u2500 healpix \u2502 \u251c\u2500\u2500 install \u2502 \u2514\u2500\u2500 Y6A2_SOF_V2.csv \u2514\u2500\u2500 Y6_Gold_2_0 \u2514\u2500\u2500 Y6_Gold_2_0 du -khs Y6A2_COADD/*/* 274M Y6A2_COADD/Y6A2_COADD/cats 0 Y6A2_COADD/Y6A2_COADD/cats_y6a2 0 Y6A2_COADD/Y6A2_COADD/fits 898G Y6A2_COADD/Y6A2_COADD/healpix 0 Y6A2_COADD/Y6A2_COADD/maps 9.1G Y6A2_COADD/Y6A2_COADD/masks 0 Y6A2_COADD/Y6A2_COADD/pngs 4.0K Y6A2_COADD/Y6A2_COADD_SMALL/healpix 4.0K Y6A2_COADD/Y6A2_COADD/stilts_converter_Y6A2-coadd_to_Y6A2-small.sh 1.7T Y6A2_COADD/Y6A2_GOLD/cats 36K Y6A2_COADD/Y6A2_GOLD/install 0 Y6A2_COADD/Y6A2_GOLD_SMALL/cats 3.2G Y6A2_COADD/Y6A2_GOLD_SMALL/healpix 196K Y6A2_COADD/Y6A2_GOLD_SMALL/install 15G Y6A2_COADD/Y6A2_GOLD/Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits 132K Y6A2_COADD/Y6A2_GOLD/Y6_Gold_2_0.csv 904G Y6A2_COADD/Y6A2_SOF_V2/cats 0 Y6A2_COADD/Y6A2_SOF_V2/healpix 14M Y6A2_COADD/Y6A2_SOF_V2/install 132K Y6A2_COADD/Y6A2_SOF_V2/Y6A2_SOF_V2.csv 0 Y6A2_COADD/Y6_Gold_2_0/Y6_Gold_2_0 - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&title=Y6A1+Release+Notes - Description: This is not a public catalog, only available for the collaboration. Y6A2 is the reprocessing of only 73 tiles after detect an issue in align DECam images (see the Y6A1 description for reference). See the list of tiles in https://desar2.cosmology.illinois.edu/DESFiles/desarchive/OPS/multiepoch/Y6A2/r5137/ . Files in Y6A2_COADD/Y6A2_COADD/healpix/32/ .fits here is the table Y6A2_COADD_OBJECT_SUMMARY available for the collaboration, with 186 columns and 691483608 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. The masks are the set list of files ( .pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps for only the tiles that changed in Y6A1 to Y6A2. Y6A2_GOLD is the catalog Y6_GOLD_2_0 version available on easyaccess. The files are split by tile in folder Y6A2_GOLD/cats. The files copied here have the same amount of 333 columns and 691483608 objects. Data access (catalogs and images): easyaccess (internal collaboration) T1 tree -L 2 . . \u251c\u2500\u2500 desar2.cosmology.illinois.edu \u2502 \u2514\u2500\u2500 DESFiles \u251c\u2500\u2500 dr2 \u2502 \u251c\u2500\u2500 fits \u2502 \u2514\u2500\u2500 ptifs \u251c\u2500\u2500 images \u2502 \u2514\u2500\u2500 y6a1_hips \u251c\u2500\u2500 process \u2502 \u251c\u2500\u2500 production \u2502 \u251c\u2500\u2500 testing \u2502 \u2514\u2500\u2500 testnagios \u251c\u2500\u2500 Y6A2_COADD \u2502 \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u2514\u2500\u2500 Y6A2_GOLD_SMALL \u251c\u2500\u2500 y6a2_gold \u2502 \u2514\u2500\u2500 cats \u251c\u2500\u2500 Y6A2_GOLD \u2502 \u2514\u2500\u2500 cats \u251c\u2500\u2500 Y6A2_GOLD_FITS \u2502 \u2514\u2500\u2500 BALANCED \u2514\u2500\u2500 Y6_SUBSET_HIPS \u251c\u2500\u2500 AladinBeta.jar \u251c\u2500\u2500 Hipsgen-cat.jar \u251c\u2500\u2500 imagens \u2514\u2500\u2500 outputs 23 directories, 2 files Getting information about datasets volume size","title":"Y6A2_COADD, Y6A2_GOLD, Y6A2_SOF (and SMALL versions)"},{"location":"data/lsst.html","text":"LSST \u00b6 Warning Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda LSST datasets available at LIneA Archive \u00b6 \u251c\u2500\u2500 calexp \u251c\u2500\u2500 cosmo_dc2 \u251c\u2500\u2500 dc2 \u251c\u2500\u2500 dp0 \u2514\u2500\u2500 images 5 directories, 0 files du -khs * 17G calexp 103G cosmo_dc2 5.5T dc2 345M dp0 36G images T1 \u00b6 tree -L 2 . . \u251c\u2500\u2500 cosmo_dc2 \u2502 \u2514\u2500\u2500 EXTRAGALACTIC \u251c\u2500\u2500 dp0 \u2502 \u2514\u2500\u2500 lsst_dp0 \u251c\u2500\u2500 dp0.2 \u2502 \u251c\u2500\u2500 log_dp0.txt \u2502 \u251c\u2500\u2500 md5sum \u2502 \u251c\u2500\u2500 objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq | \u251c\u2500\u2500 [...] 157 arquivos .parq ocultados \u2502 \u251c\u2500\u2500 objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq \u2502 \u2514\u2500\u2500 objectTable_tract.txt \u251c\u2500\u2500 dp0_skinny \u2502 \u2514\u2500\u2500 DP0 \u251c\u2500\u2500 dr1 \u251c\u2500\u2500 dr2 \u251c\u2500\u2500 gawa_project \u2502 \u251c\u2500\u2500 adriano.pieres \u2502 \u251c\u2500\u2500 input_data \u2502 \u251c\u2500\u2500 outputs \u2502 \u251c\u2500\u2500 raslan.oliveira \u2502 \u2514\u2500\u2500 singulani \u251c\u2500\u2500 tmp \u2502 \u2514\u2500\u2500 henrique.almeida \u2514\u2500\u2500 wazp_project \u251c\u2500\u2500 carlos \u251c\u2500\u2500 datasets \u251c\u2500\u2500 tiles_slices \u251c\u2500\u2500 wazp \u251c\u2500\u2500 wazp-errors.txt \u251c\u2500\u2500 wazp.log \u251c\u2500\u2500 wazp-outfile.txt \u251c\u2500\u2500 wazp_sdumont \u2514\u2500\u2500 wazp_tiles 24 directories, 163 files du -khs */* 354G cosmo_dc2/EXTRAGALACTIC 12G dp0.2/log_dp0.txt 24K dp0.2/md5sum 6.6G dp0.2/objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq [...] 157 arquivos .parq ocultados 5.9G dp0.2/objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq 32K dp0.2/objectTable_tract.txt 2.5T dp0/lsst_dp0 69G dp0_skinny/DP0","title":"LSST"},{"location":"data/lsst.html#lsst","text":"Warning Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda LSST datasets available at LIneA","title":"LSST"},{"location":"data/lsst.html#archive","text":"\u251c\u2500\u2500 calexp \u251c\u2500\u2500 cosmo_dc2 \u251c\u2500\u2500 dc2 \u251c\u2500\u2500 dp0 \u2514\u2500\u2500 images 5 directories, 0 files du -khs * 17G calexp 103G cosmo_dc2 5.5T dc2 345M dp0 36G images","title":"Archive"},{"location":"data/lsst.html#t1","text":"tree -L 2 . . \u251c\u2500\u2500 cosmo_dc2 \u2502 \u2514\u2500\u2500 EXTRAGALACTIC \u251c\u2500\u2500 dp0 \u2502 \u2514\u2500\u2500 lsst_dp0 \u251c\u2500\u2500 dp0.2 \u2502 \u251c\u2500\u2500 log_dp0.txt \u2502 \u251c\u2500\u2500 md5sum \u2502 \u251c\u2500\u2500 objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq | \u251c\u2500\u2500 [...] 157 arquivos .parq ocultados \u2502 \u251c\u2500\u2500 objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq \u2502 \u2514\u2500\u2500 objectTable_tract.txt \u251c\u2500\u2500 dp0_skinny \u2502 \u2514\u2500\u2500 DP0 \u251c\u2500\u2500 dr1 \u251c\u2500\u2500 dr2 \u251c\u2500\u2500 gawa_project \u2502 \u251c\u2500\u2500 adriano.pieres \u2502 \u251c\u2500\u2500 input_data \u2502 \u251c\u2500\u2500 outputs \u2502 \u251c\u2500\u2500 raslan.oliveira \u2502 \u2514\u2500\u2500 singulani \u251c\u2500\u2500 tmp \u2502 \u2514\u2500\u2500 henrique.almeida \u2514\u2500\u2500 wazp_project \u251c\u2500\u2500 carlos \u251c\u2500\u2500 datasets \u251c\u2500\u2500 tiles_slices \u251c\u2500\u2500 wazp \u251c\u2500\u2500 wazp-errors.txt \u251c\u2500\u2500 wazp.log \u251c\u2500\u2500 wazp-outfile.txt \u251c\u2500\u2500 wazp_sdumont \u2514\u2500\u2500 wazp_tiles 24 directories, 163 files du -khs */* 354G cosmo_dc2/EXTRAGALACTIC 12G dp0.2/log_dp0.txt 24K dp0.2/md5sum 6.6G dp0.2/objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq [...] 157 arquivos .parq ocultados 5.9G dp0.2/objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq 32K dp0.2/objectTable_tract.txt 2.5T dp0/lsst_dp0 69G dp0_skinny/DP0","title":"T1"},{"location":"exemplos/exemplos.html","text":"icons and emojis \u00b6 https://squidfunk.github.io/mkdocs-material/reference/icons-emojis/#icons-emojis Quer adicionar um destaque sem quebrar o fluxo do texto? Use admonitions! \u00b6 Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Mais exemplos de admonitions \u00b6 https://squidfunk.github.io/mkdocs-material/reference/admonitions/#usage","title":"Exemplos"},{"location":"exemplos/exemplos.html#icons-and-emojis","text":"https://squidfunk.github.io/mkdocs-material/reference/icons-emojis/#icons-emojis","title":"icons and emojis"},{"location":"exemplos/exemplos.html#quer-adicionar-um-destaque-sem-quebrar-o-fluxo-do-texto-use-admonitions","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Quer adicionar um destaque sem quebrar o fluxo do texto? Use admonitions!"},{"location":"exemplos/exemplos.html#mais-exemplos-de-admonitions","text":"https://squidfunk.github.io/mkdocs-material/reference/admonitions/#usage","title":"Mais exemplos de admonitions"},{"location":"processamento/index.html","text":"JupyterHub \u00b6 Para an\u00e1lise explorat\u00f3ria dos dados, o LIneA oferece poder de processamento atrav\u00e9s da plataforma JupyterHub. Saiba mais detalhes clicando aqui . Computa\u00e7\u00e3o de Alto Desempenho (HPC) \u00b6 O LIneA oferece acesso recursos computacionais de alto desempenho a usu\u00e1rios membros de colabora\u00e7\u00f5es cient\u00edficas e com projetos apoiados pelo laborat\u00f3rio em dois ambientes: Cluster HPE Apollo 2000 (LIneA) Supercomputador Santos Dumont (LNCC)","title":"Processamento"},{"location":"processamento/index.html#jupyterhub","text":"Para an\u00e1lise explorat\u00f3ria dos dados, o LIneA oferece poder de processamento atrav\u00e9s da plataforma JupyterHub. Saiba mais detalhes clicando aqui .","title":"JupyterHub"},{"location":"processamento/index.html#computacao-de-alto-desempenho-hpc","text":"O LIneA oferece acesso recursos computacionais de alto desempenho a usu\u00e1rios membros de colabora\u00e7\u00f5es cient\u00edficas e com projetos apoiados pelo laborat\u00f3rio em dois ambientes: Cluster HPE Apollo 2000 (LIneA) Supercomputador Santos Dumont (LNCC)","title":"Computa\u00e7\u00e3o de Alto Desempenho (HPC)"},{"location":"processamento/apollo.html","text":"HPE Apollo 2000 \u00b6 O Cluster Apollo possui 28 n\u00f3s computacionais e oferece um total de 1072 cores f\u00edsicos. Seus n\u00f3s s\u00e3o equipados com processadores Intel Xeon Skylake 5120, 14-cores, 2.2GHz (apl01-14) e Intel(R) Xeon(R) Gold 5320 CPU @ 2.20GHz (apl15-26) com o sistema de hyperthreading ativado. O conjunto de m\u00e1quinas prov\u00ea cerca de 80 Tflops de capacidade computacional. Os 28 n\u00f3s computacionais do Cluster Apollo s\u00e3o da fam\u00edlia de servidores HPE ProLiant, sendo 16 do modelo XL170r e 12 do modelo XL220n. Atualmente, o n\u00famero de cores dispon\u00edveis \u00e9 de 2144 devido o hyper-threading estar ativo nos n\u00f3s de computa\u00e7\u00e3o. Caracter\u00edsticas atuais \u00b6 # Nodes # Cores Total de ram Instalado em 16 [1] 448 2TB Abr-2019 12 624 3TB Jul-2023 [1] atualmente 2 n\u00f3s est\u00e3o sendo usados como m\u00e1quinas de servi\u00e7o do cluster . O Cluster Apollo \u00e9 gerenciado pelo Slurm version 18.08.8 . Acesso ao n\u00f3 de submiss\u00e3o \u00b6 O acesso ao host de submiss\u00e3o \u00e9 feito por chave ssh e \u00e9 necess\u00e1rio que voc\u00ea possua uma conta v\u00e1lida no LIneA. Depois de se registrar como usu\u00e1rio do LIneA ( detalhes aqui ) e receber o e-mail de confirma\u00e7\u00e3o, \u00e9 necess\u00e1rio entrar em contato com o Service Desk atrav\u00e9s do e-mail helpdesk@linea.org.br para receber orienta\u00e7\u00f5es de como acessar o n\u00f3 de submiss\u00e3o para executar tarefas no cluster. Slurm \u00b6 Slurm \u00e9 um sistema de gerenciamento de cluster e agendamento de tarefas de c\u00f3digo aberto, tolerante a falhas e altamente escalon\u00e1vel para clusters Linux grandes e pequenos. Slurm n\u00e3o requer modifica\u00e7\u00f5es no kernel para sua opera\u00e7\u00e3o e \u00e9 relativamente independente. Como gerenciador de carga de trabalho de cluster, o Slurm tem tr\u00eas fun\u00e7\u00f5es principais: alocar acesso exclusivo e/ou n\u00e3o exclusivo aos recursos (n\u00f3s de computa\u00e7\u00e3o) aos usu\u00e1rios por um determinado per\u00edodo de tempo para que possam realizar o trabalho. oferecer uma estrutura para iniciar, executar e monitorar o trabalho (normalmente um trabalho paralelo) no conjunto de n\u00f3s alocados. gerenciar a fila de submiss\u00e3o, arbitrando conflitos entre os pedidos de recursos computacionais. Filesystem \u00b6 O Cluster Apollo conta com um Filesystem Lustre, utilizado como \"Scratch\". O \"Home\" dos usu\u00e1rios (acess\u00edvel apenas no n\u00f3 de login), \u00e9 fornecido atrav\u00e9s de NFS. Essas \u00e1reas de armazenamento devem ser utilizadas da seguinte forma: Scratch : Estrutura montada a partir do diret\u00f3rio /lustre/t0/scratch/users/ . Utilizado para armazenar todos os arquivos que ser\u00e3o utilizados durante a execu\u00e7\u00e3o de um job (scripts de submiss\u00e3o, execut\u00e1veis, dados de entrada, dados de sa\u00edda etc). Home : Estrutura montada a partir do diret\u00f3rio /home/ . Utilizado para armazenar especialmente os resultados que se queira manter durante toda a vig\u00eancia do projeto. Clique aqui para mais detalhes Aten\u00e7\u00e3o N\u00e3o esque\u00e7a de copiar os arquivos necess\u00e1rios (execut\u00e1vel, bibliotecas, dados de entrada) para dentro da \u00e1rea de SCRATCH, pois a \u00e1rea de HOMEDIR n\u00e3o \u00e9 acess\u00edvel pelos n\u00f3s computacionais. Parti\u00e7\u00f5es dispon\u00edveis \u00b6 O cluster Apollo \u00e9 organizado em diferentes parti\u00e7\u00f5es (subconjunto de m\u00e1quinas) para atender a diferentes necessidades, por exemplo, a garantia da prioridade m\u00e1xima dos usu\u00e1rios do projeto LSST na utiliza\u00e7\u00e3o das m\u00e1quinas dedicadas ao IDAC-Brasil. PARTITION TIMELIMIT NODES NODELIST cpu_dev 30:00 26 apl[01-26] cpu_small 3-00:00:00 26 apl[01-26] cpu 5-00:00:00 26 apl[01-26] cpu_long 31-00:00:0 26 apl[01-26] LSST infinite 12 apl[15-26] Accounts dispon\u00edveis \u00b6 Workflow \u2013 Interrompe qualquer job que esteja rodando: hpc-photoz (photoz) LSST \u2013 Pr\u00f3ximo da fila: hpc-lsst [somente nas novas apollos apl[15-26]] (lsst) Grupo A - Prioridade Maior: hpc-bpglsst (itteam, bpg-lsst) Grupo B - Prioridade Intermedi\u00e1ria: hpc-collab (des, desi, sdss, tno) Grupo C - Prioridade Menor: hpc-public (linea-members) As parti\u00e7\u00f5es ( cpu_dev , cpu_small , cpu e cpu_long ) possuem todas as apollos ( apl[01-26] ), enquanto a parti\u00e7\u00e3o LSST possui apenas as apl[15-26] . Por\u00e9m, somente o account hpc-lsst poder\u00e1 submeter jobs nessa parti\u00e7\u00e3o ( LSST ), que possui prioridade maior nesses nodes. Aten\u00e7\u00e3o Como parte do programa de conrtribui\u00e7\u00e3o in-kind BRA-LIN, o IDAC Brasil possui o compromisso de gerar redshifts fotom\u00e9tricos anualmente para o levantamento LSST, sempre na \u00e9poca que antecede as libera\u00e7\u00f5es oficiais dos dados. Nestes per\u00edodos, o Cluster Apollo ser\u00e1 totalmente ocupado para este prop\u00f3sito por um tempo estimado de algumas horas, mas podendo se estender a alguns dias. Na ocasi\u00e3o, os usu\u00e1rios ser\u00e3o informados com antec\u00eancia sobre a indisponibilidade do cluster por e-mail. Clique aqui para saber mais sobre a produ\u00e7\u00e3o de medidas de redshift e o programa de conrtribui\u00e7\u00e3o in-kind BRA-LIN. Anatomia de um Job \u00b6 Um Job solicita recursos de computa\u00e7\u00e3o e especifica os aplicativos a serem iniciados nesses recursos, juntamente com quaisquer dados/op\u00e7\u00f5es de entrada e diretivas de sa\u00edda. O usu\u00e1rio envia a tarefa, geralmente na forma de um script de tarefa em lote, ao agendador em lote. O script de tarefa em lote \u00e9 composto por quatro componentes principais: O int\u00e9rprete usado para executar o script Diretivas \u201c#\u201d que transmitem op\u00e7\u00f5es de envio padr\u00e3o. A configura\u00e7\u00e3o de vari\u00e1veis de ambiente e/ou script (se necess\u00e1rio) Os aplicativos a serem executados junto com seus argumentos e op\u00e7\u00f5es de entrada. Aqui est\u00e1 um exemplo de um script em lote que solicita 3 n\u00f3s na parti\u00e7\u00e3o \"cpu\" e inicia 36 tarefas do myApp nos 3 n\u00f3s alocados: #!/bin/bash #SBATCH -N 3 #SBATCH -p cpu #SBATCH --ntasks 36 srun myApp Quando a tarefa estiver agendada para execu\u00e7\u00e3o, o gerenciador de recursos executar\u00e1 o script da tarefa em lote no primeiro n\u00f3 da aloca\u00e7\u00e3o. Executando um Job \u00b6 Ap\u00f3s ter constru\u00eddo o script de execu\u00e7\u00e3o com todas basta chama-lo utilizando o comando sbatch como mostra o exemplo abaixo: [ usuario@loginapl01 ] $ sbatch myscript.slurm Se o script estiver correto haver\u00e1 uma sa\u00edda que indica o ID do job. Por exemplo: [ usuario@loginapl01 ] $ sbatch myscript.slurm Submitted batch job 510 Andamento do Job \u00b6 A maioria das especifica\u00e7\u00f5es de um job pode ser vista atrav\u00e9s do comando scontrol show job <JobID> . Mais detalhes sobre o trabalho, incluindo o script do trabalho, podem ser vistos adicionando o sinalizador -d . Um usu\u00e1rio n\u00e3o consegue ver o script do trabalho de outro usu\u00e1rio. [ usuario@loginapl01 ] $ scontrol show job 510 O Slurm captura e relata o c\u00f3digo de sa\u00edda do script do job (tarefas sbatch), bem como o sinal que causou o t\u00e9rmino da execu\u00e7\u00e3o. Cancelando um Job \u00b6 Se seu Job estiver em execu\u00e7\u00e3o ou aguardando na fila, voc\u00ea poder\u00e1 cancelar o trabalho usando o comando scancel <JobId> . Use o comando squeue se voc\u00ea n\u00e3o souber o ID do Job. Por exemplo: [ usuario@loginapl01 ] $ scancel 510 Especificando Recursos \u00b6 O Slurm tem sua pr\u00f3pria sintaxe para solicitar recursos de computa\u00e7\u00e3o. Abaixo est\u00e1 uma tabela de resumo de alguns recursos solicitados com frequ\u00eancia e a sintaxe de Slurm para obt\u00ea-los. Para obter uma lista completa da sintaxe, execute o comando man sbatch. Sintaxe Significado #SBATCH -p partition Define a parti\u00e7\u00e3o em que o job ser\u00e1 executado #SBATCH -J job_name Define o nome do Job #SBATCH -n quantidade Define o n\u00famero total de tarefas da CPU. #SBATCH -N quantidade Define o n\u00famero de n\u00f3s de computa\u00e7\u00e3o solicitados. Comandos B\u00e1sicos do Slurm \u00b6 Para aprender sobre todas as op\u00e7\u00f5es dispon\u00edveis para cada comando, insira man enquanto estiver conectado ao ambiente do Cluster. Comando Defini\u00e7\u00e3o sbatch Envia scripts de tarefas para a fila de execu\u00e7\u00e3o scancel Cancela um job scontrol Usado para exibir o estado Slurm (v\u00e1rias op\u00e7\u00f5es dispon\u00edveis apenas para root) sinfo Exibir estado de parti\u00e7\u00f5es e n\u00f3s squeue Exibir estado dos jobs salloc Envia um job para execu\u00e7\u00e3o ou inicia um trabalho em tempo real Ambiente de Execu\u00e7\u00e3o \u00b6 Para cada tipo de trabalho acima, o usu\u00e1rio tem a capacidade de definir o ambiente de execu\u00e7\u00e3o. Isso inclui defini\u00e7\u00f5es de vari\u00e1veis de ambiente, bem como limites de shell ( bash ulimit ou csh limit ). sbatch e salloc fornecem a op\u00e7\u00e3o --export para transmitir vari\u00e1veis de ambiente espec\u00edficas para o ambiente de execu\u00e7\u00e3o. E tamb\u00e9m tem a op\u00e7\u00e3o --propagate para transmitir limites espec\u00edficos do shell ao ambiente de execu\u00e7\u00e3o. Vari\u00e1veis de \u200b\u200bambiente \u00b6 A primeira categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o Slurm insere no ambiente de execu\u00e7\u00e3o do trabalho. Eles transmitem ao script da tarefa e informa\u00e7\u00f5es do aplicativo, como ID da tarefa (SLURM_JOB_ID) e ID da tarefa (SLURM_PROCID) . Para obter a lista completa, consulte a se\u00e7\u00e3o \"OUTPUT ENVIRONMENT VARIABLES\" nas p\u00e1ginas sbatch , salloc e srun . A pr\u00f3xima categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o usu\u00e1rio pode definir em seu ambiente para transmitir op\u00e7\u00f5es padr\u00e3o para cada trabalho enviado. Isso inclui op\u00e7\u00f5es como o limite do rel\u00f3gio de parede. Para obter a lista completa, consulte a se\u00e7\u00e3o \"INPUT ENVIRONMENT VARIABLES\" nas p\u00e1ginas sbatch , salloc e srun . Gerenciamento de pacotes (EUPS) \u00b6 O EUPS \u00e9 um gerenciador de pacotes alternativo (e oficial do LSST) que permite carregar vari\u00e1veis de ambiente e incluir o caminho para programas e bibliotecas de forma modular: Attention Esses comandos dever\u00e3o ser executados dentro do ambiente LIneA. Para carregar o EUPS: . /mnt/eups/linea_eups_setup.sh Listar todos os pacotes dispon\u00edveis: eups list Carregar um pacote na sess\u00e3o atual: setup scipy 0 .11.0+2 Remover um pacote da sess\u00e3o atual: unsetup scipy 0 .11.0+2","title":"Cluster Apollo (LIneA)"},{"location":"processamento/apollo.html#hpe-apollo-2000","text":"O Cluster Apollo possui 28 n\u00f3s computacionais e oferece um total de 1072 cores f\u00edsicos. Seus n\u00f3s s\u00e3o equipados com processadores Intel Xeon Skylake 5120, 14-cores, 2.2GHz (apl01-14) e Intel(R) Xeon(R) Gold 5320 CPU @ 2.20GHz (apl15-26) com o sistema de hyperthreading ativado. O conjunto de m\u00e1quinas prov\u00ea cerca de 80 Tflops de capacidade computacional. Os 28 n\u00f3s computacionais do Cluster Apollo s\u00e3o da fam\u00edlia de servidores HPE ProLiant, sendo 16 do modelo XL170r e 12 do modelo XL220n. Atualmente, o n\u00famero de cores dispon\u00edveis \u00e9 de 2144 devido o hyper-threading estar ativo nos n\u00f3s de computa\u00e7\u00e3o.","title":"HPE Apollo 2000"},{"location":"processamento/apollo.html#caracteristicas-atuais","text":"# Nodes # Cores Total de ram Instalado em 16 [1] 448 2TB Abr-2019 12 624 3TB Jul-2023 [1] atualmente 2 n\u00f3s est\u00e3o sendo usados como m\u00e1quinas de servi\u00e7o do cluster . O Cluster Apollo \u00e9 gerenciado pelo Slurm version 18.08.8 .","title":"Caracter\u00edsticas atuais"},{"location":"processamento/apollo.html#acesso-ao-no-de-submissao","text":"O acesso ao host de submiss\u00e3o \u00e9 feito por chave ssh e \u00e9 necess\u00e1rio que voc\u00ea possua uma conta v\u00e1lida no LIneA. Depois de se registrar como usu\u00e1rio do LIneA ( detalhes aqui ) e receber o e-mail de confirma\u00e7\u00e3o, \u00e9 necess\u00e1rio entrar em contato com o Service Desk atrav\u00e9s do e-mail helpdesk@linea.org.br para receber orienta\u00e7\u00f5es de como acessar o n\u00f3 de submiss\u00e3o para executar tarefas no cluster.","title":"Acesso ao n\u00f3 de submiss\u00e3o"},{"location":"processamento/apollo.html#slurm","text":"Slurm \u00e9 um sistema de gerenciamento de cluster e agendamento de tarefas de c\u00f3digo aberto, tolerante a falhas e altamente escalon\u00e1vel para clusters Linux grandes e pequenos. Slurm n\u00e3o requer modifica\u00e7\u00f5es no kernel para sua opera\u00e7\u00e3o e \u00e9 relativamente independente. Como gerenciador de carga de trabalho de cluster, o Slurm tem tr\u00eas fun\u00e7\u00f5es principais: alocar acesso exclusivo e/ou n\u00e3o exclusivo aos recursos (n\u00f3s de computa\u00e7\u00e3o) aos usu\u00e1rios por um determinado per\u00edodo de tempo para que possam realizar o trabalho. oferecer uma estrutura para iniciar, executar e monitorar o trabalho (normalmente um trabalho paralelo) no conjunto de n\u00f3s alocados. gerenciar a fila de submiss\u00e3o, arbitrando conflitos entre os pedidos de recursos computacionais.","title":"Slurm"},{"location":"processamento/apollo.html#filesystem","text":"O Cluster Apollo conta com um Filesystem Lustre, utilizado como \"Scratch\". O \"Home\" dos usu\u00e1rios (acess\u00edvel apenas no n\u00f3 de login), \u00e9 fornecido atrav\u00e9s de NFS. Essas \u00e1reas de armazenamento devem ser utilizadas da seguinte forma: Scratch : Estrutura montada a partir do diret\u00f3rio /lustre/t0/scratch/users/ . Utilizado para armazenar todos os arquivos que ser\u00e3o utilizados durante a execu\u00e7\u00e3o de um job (scripts de submiss\u00e3o, execut\u00e1veis, dados de entrada, dados de sa\u00edda etc). Home : Estrutura montada a partir do diret\u00f3rio /home/ . Utilizado para armazenar especialmente os resultados que se queira manter durante toda a vig\u00eancia do projeto. Clique aqui para mais detalhes Aten\u00e7\u00e3o N\u00e3o esque\u00e7a de copiar os arquivos necess\u00e1rios (execut\u00e1vel, bibliotecas, dados de entrada) para dentro da \u00e1rea de SCRATCH, pois a \u00e1rea de HOMEDIR n\u00e3o \u00e9 acess\u00edvel pelos n\u00f3s computacionais.","title":"Filesystem"},{"location":"processamento/apollo.html#particoes-disponiveis","text":"O cluster Apollo \u00e9 organizado em diferentes parti\u00e7\u00f5es (subconjunto de m\u00e1quinas) para atender a diferentes necessidades, por exemplo, a garantia da prioridade m\u00e1xima dos usu\u00e1rios do projeto LSST na utiliza\u00e7\u00e3o das m\u00e1quinas dedicadas ao IDAC-Brasil. PARTITION TIMELIMIT NODES NODELIST cpu_dev 30:00 26 apl[01-26] cpu_small 3-00:00:00 26 apl[01-26] cpu 5-00:00:00 26 apl[01-26] cpu_long 31-00:00:0 26 apl[01-26] LSST infinite 12 apl[15-26]","title":"Parti\u00e7\u00f5es dispon\u00edveis"},{"location":"processamento/apollo.html#accounts-disponiveis","text":"Workflow \u2013 Interrompe qualquer job que esteja rodando: hpc-photoz (photoz) LSST \u2013 Pr\u00f3ximo da fila: hpc-lsst [somente nas novas apollos apl[15-26]] (lsst) Grupo A - Prioridade Maior: hpc-bpglsst (itteam, bpg-lsst) Grupo B - Prioridade Intermedi\u00e1ria: hpc-collab (des, desi, sdss, tno) Grupo C - Prioridade Menor: hpc-public (linea-members) As parti\u00e7\u00f5es ( cpu_dev , cpu_small , cpu e cpu_long ) possuem todas as apollos ( apl[01-26] ), enquanto a parti\u00e7\u00e3o LSST possui apenas as apl[15-26] . Por\u00e9m, somente o account hpc-lsst poder\u00e1 submeter jobs nessa parti\u00e7\u00e3o ( LSST ), que possui prioridade maior nesses nodes. Aten\u00e7\u00e3o Como parte do programa de conrtribui\u00e7\u00e3o in-kind BRA-LIN, o IDAC Brasil possui o compromisso de gerar redshifts fotom\u00e9tricos anualmente para o levantamento LSST, sempre na \u00e9poca que antecede as libera\u00e7\u00f5es oficiais dos dados. Nestes per\u00edodos, o Cluster Apollo ser\u00e1 totalmente ocupado para este prop\u00f3sito por um tempo estimado de algumas horas, mas podendo se estender a alguns dias. Na ocasi\u00e3o, os usu\u00e1rios ser\u00e3o informados com antec\u00eancia sobre a indisponibilidade do cluster por e-mail. Clique aqui para saber mais sobre a produ\u00e7\u00e3o de medidas de redshift e o programa de conrtribui\u00e7\u00e3o in-kind BRA-LIN.","title":"Accounts dispon\u00edveis"},{"location":"processamento/apollo.html#anatomia-de-um-job","text":"Um Job solicita recursos de computa\u00e7\u00e3o e especifica os aplicativos a serem iniciados nesses recursos, juntamente com quaisquer dados/op\u00e7\u00f5es de entrada e diretivas de sa\u00edda. O usu\u00e1rio envia a tarefa, geralmente na forma de um script de tarefa em lote, ao agendador em lote. O script de tarefa em lote \u00e9 composto por quatro componentes principais: O int\u00e9rprete usado para executar o script Diretivas \u201c#\u201d que transmitem op\u00e7\u00f5es de envio padr\u00e3o. A configura\u00e7\u00e3o de vari\u00e1veis de ambiente e/ou script (se necess\u00e1rio) Os aplicativos a serem executados junto com seus argumentos e op\u00e7\u00f5es de entrada. Aqui est\u00e1 um exemplo de um script em lote que solicita 3 n\u00f3s na parti\u00e7\u00e3o \"cpu\" e inicia 36 tarefas do myApp nos 3 n\u00f3s alocados: #!/bin/bash #SBATCH -N 3 #SBATCH -p cpu #SBATCH --ntasks 36 srun myApp Quando a tarefa estiver agendada para execu\u00e7\u00e3o, o gerenciador de recursos executar\u00e1 o script da tarefa em lote no primeiro n\u00f3 da aloca\u00e7\u00e3o.","title":"Anatomia de um Job"},{"location":"processamento/apollo.html#executando-um-job","text":"Ap\u00f3s ter constru\u00eddo o script de execu\u00e7\u00e3o com todas basta chama-lo utilizando o comando sbatch como mostra o exemplo abaixo: [ usuario@loginapl01 ] $ sbatch myscript.slurm Se o script estiver correto haver\u00e1 uma sa\u00edda que indica o ID do job. Por exemplo: [ usuario@loginapl01 ] $ sbatch myscript.slurm Submitted batch job 510","title":"Executando um Job"},{"location":"processamento/apollo.html#andamento-do-job","text":"A maioria das especifica\u00e7\u00f5es de um job pode ser vista atrav\u00e9s do comando scontrol show job <JobID> . Mais detalhes sobre o trabalho, incluindo o script do trabalho, podem ser vistos adicionando o sinalizador -d . Um usu\u00e1rio n\u00e3o consegue ver o script do trabalho de outro usu\u00e1rio. [ usuario@loginapl01 ] $ scontrol show job 510 O Slurm captura e relata o c\u00f3digo de sa\u00edda do script do job (tarefas sbatch), bem como o sinal que causou o t\u00e9rmino da execu\u00e7\u00e3o.","title":"Andamento do Job"},{"location":"processamento/apollo.html#cancelando-um-job","text":"Se seu Job estiver em execu\u00e7\u00e3o ou aguardando na fila, voc\u00ea poder\u00e1 cancelar o trabalho usando o comando scancel <JobId> . Use o comando squeue se voc\u00ea n\u00e3o souber o ID do Job. Por exemplo: [ usuario@loginapl01 ] $ scancel 510","title":"Cancelando um Job"},{"location":"processamento/apollo.html#especificando-recursos","text":"O Slurm tem sua pr\u00f3pria sintaxe para solicitar recursos de computa\u00e7\u00e3o. Abaixo est\u00e1 uma tabela de resumo de alguns recursos solicitados com frequ\u00eancia e a sintaxe de Slurm para obt\u00ea-los. Para obter uma lista completa da sintaxe, execute o comando man sbatch. Sintaxe Significado #SBATCH -p partition Define a parti\u00e7\u00e3o em que o job ser\u00e1 executado #SBATCH -J job_name Define o nome do Job #SBATCH -n quantidade Define o n\u00famero total de tarefas da CPU. #SBATCH -N quantidade Define o n\u00famero de n\u00f3s de computa\u00e7\u00e3o solicitados.","title":"Especificando Recursos"},{"location":"processamento/apollo.html#comandos-basicos-do-slurm","text":"Para aprender sobre todas as op\u00e7\u00f5es dispon\u00edveis para cada comando, insira man enquanto estiver conectado ao ambiente do Cluster. Comando Defini\u00e7\u00e3o sbatch Envia scripts de tarefas para a fila de execu\u00e7\u00e3o scancel Cancela um job scontrol Usado para exibir o estado Slurm (v\u00e1rias op\u00e7\u00f5es dispon\u00edveis apenas para root) sinfo Exibir estado de parti\u00e7\u00f5es e n\u00f3s squeue Exibir estado dos jobs salloc Envia um job para execu\u00e7\u00e3o ou inicia um trabalho em tempo real","title":"Comandos B\u00e1sicos do Slurm"},{"location":"processamento/apollo.html#ambiente-de-execucao","text":"Para cada tipo de trabalho acima, o usu\u00e1rio tem a capacidade de definir o ambiente de execu\u00e7\u00e3o. Isso inclui defini\u00e7\u00f5es de vari\u00e1veis de ambiente, bem como limites de shell ( bash ulimit ou csh limit ). sbatch e salloc fornecem a op\u00e7\u00e3o --export para transmitir vari\u00e1veis de ambiente espec\u00edficas para o ambiente de execu\u00e7\u00e3o. E tamb\u00e9m tem a op\u00e7\u00e3o --propagate para transmitir limites espec\u00edficos do shell ao ambiente de execu\u00e7\u00e3o.","title":"Ambiente de Execu\u00e7\u00e3o"},{"location":"processamento/apollo.html#variaveis-de-ambiente","text":"A primeira categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o Slurm insere no ambiente de execu\u00e7\u00e3o do trabalho. Eles transmitem ao script da tarefa e informa\u00e7\u00f5es do aplicativo, como ID da tarefa (SLURM_JOB_ID) e ID da tarefa (SLURM_PROCID) . Para obter a lista completa, consulte a se\u00e7\u00e3o \"OUTPUT ENVIRONMENT VARIABLES\" nas p\u00e1ginas sbatch , salloc e srun . A pr\u00f3xima categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o usu\u00e1rio pode definir em seu ambiente para transmitir op\u00e7\u00f5es padr\u00e3o para cada trabalho enviado. Isso inclui op\u00e7\u00f5es como o limite do rel\u00f3gio de parede. Para obter a lista completa, consulte a se\u00e7\u00e3o \"INPUT ENVIRONMENT VARIABLES\" nas p\u00e1ginas sbatch , salloc e srun .","title":"Vari\u00e1veis de \u200b\u200bambiente"},{"location":"processamento/apollo.html#gerenciamento-de-pacotes-eups","text":"O EUPS \u00e9 um gerenciador de pacotes alternativo (e oficial do LSST) que permite carregar vari\u00e1veis de ambiente e incluir o caminho para programas e bibliotecas de forma modular: Attention Esses comandos dever\u00e3o ser executados dentro do ambiente LIneA. Para carregar o EUPS: . /mnt/eups/linea_eups_setup.sh Listar todos os pacotes dispon\u00edveis: eups list Carregar um pacote na sess\u00e3o atual: setup scipy 0 .11.0+2 Remover um pacote da sess\u00e3o atual: unsetup scipy 0 .11.0+2","title":"Gerenciamento de pacotes (EUPS)"},{"location":"processamento/sdu.html","text":"O LIneA possui um projeto \"guarda-chuva\" aprovado no LNCC chamado \" Explorando o Universo via big data: do sistema solar \u00e0 energia escura \" (sigla EUBD) que garante o direito \u00e0 utiliza\u00e7\u00e3o de 2 milh\u00f5es de horas de CPU do supercomputador Santos Dumont para apoiar alguns subprojetos que dependem de High-Performance Computing (HPC) nas seguintes \u00e1reas: Sistema Solar Via-L\u00e1ctea/Volume Local Energia Escura Estruturas de Larga Escala Redshifts Fotom\u00e9tricos (programa de contribui\u00e7\u00f5es in-kind LSST) Info Caso seu projeto tenha demandas de HPC e ainda n\u00e3o fa\u00e7a parte do escopo do projeto EUBD, entre em contato conosco atrav\u00e9s do e-mail helpdesk@linea.org.br para receber orienta\u00e7\u00f5es. Registro de usu\u00e1rios para o acesso ao Super Computador - Projeto EUBD \u00b6 Envie um e-mail, seguindo o modelo abaixo para helpdesk@linea.org.br e aguarde o nosso retorno (no m\u00e1ximo em at\u00e9 72hs).: a.) No campo assunto escreva: Acesso ao supercomputador Santos Dumont - Projeto EUBD b.) No corpo do email: 1. Seu nome completo: 2. Nome da institui\u00e7\u00e3o (acr\u00f4nimo): 3. Nome do orientador (se houver): 4. E-mail do orientador/supervisor (se houver): 5. Justificativa de uso: - Escreva em no m\u00e1ximo 5 linhas qual \u00e9 o objetivo e a import\u00e2ncia de uso desses recursos computacionais. - Se poss\u00edvel, informe quantas CPU/horas pretende utilizar e tamb\u00e9m qual o volume de dados de entrada e de sa\u00edda da sua aplica\u00e7\u00e3o. - Utilize KiloBytes(KB), MegaBytes(MB) ou GigaBytes(GB) para representar o volume de seus dados. Acesso ao supercomputador \u00b6 Ap\u00f3s a obten\u00e7\u00e3o das suas credenciais o acesso dever\u00e1 ser feito em duas etapas: Conectar-se ao servi\u00e7o de VPN do SDumont (Manuais em PDF: MAC , Linux , Windows ) Conectar-se, via SSH, ao host login.sdumont.lncc.br ( $ ssh <seu.nome.de.usuario>@login.sdumont.lncc.br ) A submiss\u00e3o dos jobs ser\u00e1 feita atrav\u00e9s do gerenciador de recursos e filas Slurm. O manual de utiliza\u00e7\u00e3o do usu\u00e1rio est\u00e1 dispon\u00edvel na p\u00e1gina do Santos Dumont no site do LNCC .","title":"Santos Dumont (LNCC)"},{"location":"processamento/sdu.html#registro-de-usuarios-para-o-acesso-ao-super-computador-projeto-eubd","text":"Envie um e-mail, seguindo o modelo abaixo para helpdesk@linea.org.br e aguarde o nosso retorno (no m\u00e1ximo em at\u00e9 72hs).: a.) No campo assunto escreva: Acesso ao supercomputador Santos Dumont - Projeto EUBD b.) No corpo do email: 1. Seu nome completo: 2. Nome da institui\u00e7\u00e3o (acr\u00f4nimo): 3. Nome do orientador (se houver): 4. E-mail do orientador/supervisor (se houver): 5. Justificativa de uso: - Escreva em no m\u00e1ximo 5 linhas qual \u00e9 o objetivo e a import\u00e2ncia de uso desses recursos computacionais. - Se poss\u00edvel, informe quantas CPU/horas pretende utilizar e tamb\u00e9m qual o volume de dados de entrada e de sa\u00edda da sua aplica\u00e7\u00e3o. - Utilize KiloBytes(KB), MegaBytes(MB) ou GigaBytes(GB) para representar o volume de seus dados.","title":"Registro de usu\u00e1rios para o acesso ao Super Computador - Projeto EUBD"},{"location":"processamento/sdu.html#acesso-ao-supercomputador","text":"Ap\u00f3s a obten\u00e7\u00e3o das suas credenciais o acesso dever\u00e1 ser feito em duas etapas: Conectar-se ao servi\u00e7o de VPN do SDumont (Manuais em PDF: MAC , Linux , Windows ) Conectar-se, via SSH, ao host login.sdumont.lncc.br ( $ ssh <seu.nome.de.usuario>@login.sdumont.lncc.br ) A submiss\u00e3o dos jobs ser\u00e1 feita atrav\u00e9s do gerenciador de recursos e filas Slurm. O manual de utiliza\u00e7\u00e3o do usu\u00e1rio est\u00e1 dispon\u00edvel na p\u00e1gina do Santos Dumont no site do LNCC .","title":"Acesso ao supercomputador"},{"location":"sci-platforms/index.html","text":"LIneA Science Platform (LSP) \u00b6 O LIneA Science Platform, ou LSP ( lsp.linea.org.br ), \u00e9 uma plataforma online que agrega um conjunto de servi\u00e7os e ferramentas oferecidas para facilitar o acesso e a an\u00e1lise dos dados astron\u00f4micos hospedados no LIneA. Clique aqui para saber mais sobre o LSP. Durante a opera\u00e7\u00e3o do levantamento LSST , o LSP ser\u00e1 o principal ponto de acesso aos dados para os cientistas da comunidade Brasileira, tanto para os membros do Brazilian Participation Group (BPG), que ter\u00e3o acesso aos dados propriet\u00e1rios a cada data release , e para os demais cientistas, que ter\u00e3o acesso apenas aos dados p\u00fablicos ap\u00f3s o per\u00edodo de embargo estabelecido pelo levantamento. O LSP vai oferecer acesso aos dados hospedados no Brazilian Independent Data Access Center (IDAC), cumprindo papel semelhante ao da plataforma Rubin Science Platform (RSP) no Data Access Center estadunidense. Clique aqui para saber mais sobre o gerenciamento de dados do LSST na p\u00e1gina do Vera C. Rubin Observatory . Nos anos que antecedem a opera\u00e7\u00e3o do LSST, o LSP (que ainda est\u00e1 em fase de desenvolvimento) j\u00e1 disponibiliza acesso a dados que s\u00e3o p\u00fablicos, como por exemplo o segundo data release do levantamento Dark Energy Survey (DES DR2), para que a comunidade possa se preparar e se familiarizar com as diversas ferramentas oferecidas. Para dados embargados, o acesso depende de credenciais espec\u00edficas. Para saber como criar uma conta no LIneA e ter acesso aos dados, leia a se\u00e7\u00e3o Primeiros Passos . Servi\u00e7os oferecidos: \u00b6 JupyterHub \u00b6 Science Server \u00b6 User Query \u00b6 Portais Cient\u00edficos \u00b6 Os portais cient\u00edficos oferecem ferramentas de processamento e visualiza\u00e7\u00e3o de dados desenvolvidas especificamente para cada projeto e s\u00e3o de uso restrito dos membros de cada colabora\u00e7\u00e3o. DES Science Portal \u00b6 SSO Portal \u00b6 MaNGA Portal \u00b6","title":"Plataformas Cient\u00edficas"},{"location":"sci-platforms/index.html#linea-science-platform-lsp","text":"O LIneA Science Platform, ou LSP ( lsp.linea.org.br ), \u00e9 uma plataforma online que agrega um conjunto de servi\u00e7os e ferramentas oferecidas para facilitar o acesso e a an\u00e1lise dos dados astron\u00f4micos hospedados no LIneA. Clique aqui para saber mais sobre o LSP. Durante a opera\u00e7\u00e3o do levantamento LSST , o LSP ser\u00e1 o principal ponto de acesso aos dados para os cientistas da comunidade Brasileira, tanto para os membros do Brazilian Participation Group (BPG), que ter\u00e3o acesso aos dados propriet\u00e1rios a cada data release , e para os demais cientistas, que ter\u00e3o acesso apenas aos dados p\u00fablicos ap\u00f3s o per\u00edodo de embargo estabelecido pelo levantamento. O LSP vai oferecer acesso aos dados hospedados no Brazilian Independent Data Access Center (IDAC), cumprindo papel semelhante ao da plataforma Rubin Science Platform (RSP) no Data Access Center estadunidense. Clique aqui para saber mais sobre o gerenciamento de dados do LSST na p\u00e1gina do Vera C. Rubin Observatory . Nos anos que antecedem a opera\u00e7\u00e3o do LSST, o LSP (que ainda est\u00e1 em fase de desenvolvimento) j\u00e1 disponibiliza acesso a dados que s\u00e3o p\u00fablicos, como por exemplo o segundo data release do levantamento Dark Energy Survey (DES DR2), para que a comunidade possa se preparar e se familiarizar com as diversas ferramentas oferecidas. Para dados embargados, o acesso depende de credenciais espec\u00edficas. Para saber como criar uma conta no LIneA e ter acesso aos dados, leia a se\u00e7\u00e3o Primeiros Passos .","title":"LIneA Science Platform (LSP)"},{"location":"sci-platforms/index.html#servicos-oferecidos","text":"","title":"Servi\u00e7os oferecidos:"},{"location":"sci-platforms/index.html#jupyterhub","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; JupyterHub"},{"location":"sci-platforms/index.html#science-server","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; Science Server"},{"location":"sci-platforms/index.html#user-query","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; User Query"},{"location":"sci-platforms/index.html#portais-cientificos","text":"Os portais cient\u00edficos oferecem ferramentas de processamento e visualiza\u00e7\u00e3o de dados desenvolvidas especificamente para cada projeto e s\u00e3o de uso restrito dos membros de cada colabora\u00e7\u00e3o.","title":"Portais Cient\u00edficos"},{"location":"sci-platforms/index.html#des-science-portal","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; DES Science Portal"},{"location":"sci-platforms/index.html#sso-portal","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; SSO Portal"},{"location":"sci-platforms/index.html#manga-portal","text":"","title":"&nbsp;&nbsp;&nbsp;&nbsp; MaNGA Portal"},{"location":"sci-platforms/des.html","text":"O DES Science Portal ( des-portal.linea.org.br/ ) \u00e9 uma plataforma desenvolvida para o projeto Dark Energy Survey. Ele hospeda uma variedade de pipelines destinados a preparar cat\u00e1logos customizados para diferentes aplica\u00e7\u00f5es na astronomia, bem como para realizar uma variedade de an\u00e1lises cient\u00edficas. Os pipelines s\u00e3o agrupados em etapas: Data Preparation - que inclui a cria\u00e7\u00e3o de mapas de efeitos sistem\u00e1ticos, classifica\u00e7\u00e3o de objetos (estrela/gal\u00e1xia), c\u00e1lculo de redshifts fotom\u00e9tricos e outros valores agregados dependendo da aplica\u00e7\u00e3o. Por exemplo, estimativa de idade, metalicidade ou massa estelar de gal\u00e1xias. Value-added Catalog - combina os dados e resultados obtidos na etapa anterior, seleciona as colunas de interesse e aplica cortes de qualidade e limpeza dos dados, com crit\u00e9rios fortemente dependentes da aplica\u00e7\u00e3o cient\u00edfica para a qual o cat\u00e1logo ser\u00e1 destinado. Science Workflows - agrega diversos pipelines de an\u00e1lise cient\u00edfica. Tem como dados de entrada os cat\u00e1logos criados na etapa anterior. Um dos principais pontos fortes do DES Science Portal \u00e9 a capacidade de fornecer informa\u00e7\u00f5es completas de todo o hist\u00f3rico de processos executados, permitindo ao usu\u00e1rio rastrear a entrada, a configura\u00e7\u00e3o, a vers\u00e3o dos c\u00f3digos utilizados e os resultados obtidos na forma de um registro do produto com gr\u00e1ficos e tabelas informativas. O portal tamb\u00e9m fornece acesso a uma s\u00e9rie de ferramentas destinadas ao usu\u00e1rio, ao desenvolvedor e ao administrador. Para se aprofundar nos detalhes sobre o DES Science Portal, leia os dois artigos publicados na revista Astronomy and Computing : Gschwend et al. 2018 - DES science portal: Computing photometric redshifts ( doi.org/10.1016/j.ascom.2018.08.008 ) ( arXiv:1708.05643 ) Fausti Neto et al. 2018 - DES science portal: Creating science-ready catalogs ( doi.org/10.1016/j.ascom.2018.01.002 ) ( arXiv:1708.05642 )","title":"DES Science Portal"},{"location":"sci-platforms/jupyter.html","text":"O JupyterHub \u00e9 um ambiente de desenvolvimento multiusu\u00e1rio baseado em iPython Notebooks que oferece acesso a recursos computacionais compartilhados em um servidor remoto, sem a necessidade de instala\u00e7\u00e3o e manuten\u00e7\u00e3o por parte dos usu\u00e1rios. Os \u00fanicos pr\u00e9-requisitos para acessar o JupyterHub s\u00e3o: ter uma conta de usu\u00e1rio no LIneA (veja aqui como criar sua conta) e um navegador com acesso \u00e0 Internet. Os chamados Jupyter Notebooks permitem combinar c\u00f3digo interativo, resultados de execu\u00e7\u00e3o, texto explicativo e recursos de multim\u00eddia em um s\u00f3 documento. Como parte do LIneA Science Platform , o LIneA JupyterHub est\u00e1 integrado \u00e0s demais ferramentas de visualiza\u00e7\u00e3o ( Science Server ) e acesso a dados ( User Query ). Desse modo, toda a an\u00e1lise de dados pode ser feita online dentro da plataforma, desde a leitura, visualiza\u00e7\u00e3o, processamento e an\u00e1lise de resultados, sem a necessidade de download dos dados. Ao clicar no card \"JupyterHub\" dentro do LIneA Science Platform, voc\u00ea ser\u00e1 direcionado para a p\u00e1gina de login e em seguida para a p\u00e1gina inicial do JupyterHub que mostrar\u00e1 o seu perfil de usu\u00e1rio. Clique no bot\u00e3o START para iniciar. A instala\u00e7\u00e3o padr\u00e3o do JupyterHub utiliza a nova interface JupyterLab e \u00e9 baseada na imagem datascience-notebook , estendida com as bibliotecas Astropy e dblinea (a biblioteca que faz a conex\u00e3o com o banco de dados). Isto significa que uma s\u00e9rie de bibliotecas Python de grande popularidade como Numpy e Matplotlib estar\u00e3o automaticamente dispon\u00edveis. Apoio ao usu\u00e1rio \u00b6 Tutoriais em Jupyter Notebooks \u00b6 No reposit\u00f3rio jupyterhub-tutorial voc\u00ea encontrar\u00e1 os tutoriais em formato notebook : 1-primeiros-passos.ipynb \u00b6 Instru\u00e7\u00f5es gerais de uso da plataforma JupyterLab, dicas e atalhos na escrita de notebooks para diferentes tipos de c\u00e9lulas. 2-acesso-a-dados.ipynb \u00b6 Instru\u00e7\u00f5es para uso da biblioteca dblinea para leitura de dados a partir do banco de dados diretamente de dentro de uma c\u00e9lula no notebook com exemplo de uso (constru\u00e7\u00e3o de um diagrama cor-magnitude simples para uma amostra de estrelas). 3-conda-env.ipynb \u00b6 Instru\u00e7\u00f5es para cria\u00e7\u00e3o de ambientes no conda para gerenciamento de bibliotecas que sejam persistentes e sobrevivam a destrui\u00e7\u00e3o e recria\u00e7\u00e3o dos containers para que os usu\u00e1rios possam retornar em uma nova sess\u00e3o e encontrar o mesmo ambiente da sess\u00e3o anterior (n\u00e3o dispon\u00edvel para usu\u00e1rios de perfil p\u00fablico bronze). Para acessar os notebooks , basta abrir um Terminal no JupyterLab clicando no bot\u00e3o \"+\" na barra superior e em seguida no \u00edcone \"Terminal\" da se\u00e7\u00e3o \"Other\" na aba \"Launcher\", e inserir o comando: git clone https://github.com/linea-it/jupyterhub-tutorial.git Tutoriais em v\u00eddeo \u00b6 Para ter acesso a tutoriais em v\u00eddeo, visite a p\u00e1gina de tutoriais do LIneA Science Platform . Minicurso \u00b6 Como parte das atividades do programa de Inicia\u00e7\u00e3o Cient\u00edfica (IC), em 2022 o LIneA ofereceu uma s\u00e9rie de minicursos para os estudantes e demais interessados com aulas remotas e atividades pr\u00e1ticas propostas. Os v\u00eddeos das aulas est\u00e3o dispon\u00edveis na p\u00e1gina do Minicurso Jupyter Notebook no Google Classroom.","title":"JupyterHub"},{"location":"sci-platforms/jupyter.html#apoio-ao-usuario","text":"","title":"Apoio ao usu\u00e1rio"},{"location":"sci-platforms/jupyter.html#tutoriais-em-jupyter-notebooks","text":"No reposit\u00f3rio jupyterhub-tutorial voc\u00ea encontrar\u00e1 os tutoriais em formato notebook :","title":"Tutoriais em Jupyter Notebooks"},{"location":"sci-platforms/jupyter.html#1-primeiros-passosipynb","text":"Instru\u00e7\u00f5es gerais de uso da plataforma JupyterLab, dicas e atalhos na escrita de notebooks para diferentes tipos de c\u00e9lulas.","title":"1-primeiros-passos.ipynb"},{"location":"sci-platforms/jupyter.html#2-acesso-a-dadosipynb","text":"Instru\u00e7\u00f5es para uso da biblioteca dblinea para leitura de dados a partir do banco de dados diretamente de dentro de uma c\u00e9lula no notebook com exemplo de uso (constru\u00e7\u00e3o de um diagrama cor-magnitude simples para uma amostra de estrelas).","title":"2-acesso-a-dados.ipynb"},{"location":"sci-platforms/jupyter.html#3-conda-envipynb","text":"Instru\u00e7\u00f5es para cria\u00e7\u00e3o de ambientes no conda para gerenciamento de bibliotecas que sejam persistentes e sobrevivam a destrui\u00e7\u00e3o e recria\u00e7\u00e3o dos containers para que os usu\u00e1rios possam retornar em uma nova sess\u00e3o e encontrar o mesmo ambiente da sess\u00e3o anterior (n\u00e3o dispon\u00edvel para usu\u00e1rios de perfil p\u00fablico bronze). Para acessar os notebooks , basta abrir um Terminal no JupyterLab clicando no bot\u00e3o \"+\" na barra superior e em seguida no \u00edcone \"Terminal\" da se\u00e7\u00e3o \"Other\" na aba \"Launcher\", e inserir o comando: git clone https://github.com/linea-it/jupyterhub-tutorial.git","title":"3-conda-env.ipynb"},{"location":"sci-platforms/jupyter.html#tutoriais-em-video","text":"Para ter acesso a tutoriais em v\u00eddeo, visite a p\u00e1gina de tutoriais do LIneA Science Platform .","title":"Tutoriais em v\u00eddeo"},{"location":"sci-platforms/jupyter.html#minicurso","text":"Como parte das atividades do programa de Inicia\u00e7\u00e3o Cient\u00edfica (IC), em 2022 o LIneA ofereceu uma s\u00e9rie de minicursos para os estudantes e demais interessados com aulas remotas e atividades pr\u00e1ticas propostas. Os v\u00eddeos das aulas est\u00e3o dispon\u00edveis na p\u00e1gina do Minicurso Jupyter Notebook no Google Classroom.","title":"Minicurso"},{"location":"sci-platforms/manga.html","text":"O portal MaNGA ( https://manga.linea.org.br/ ) foi desenvolvido para atender \u00e0s necessidades dos membros do Brazilian Participation Group do levantamento MaNGA do Sloan Digital Sky Survey. O sistema foi projetado para permitir que a equipe visualize, n\u00e3o apenas os cubos de dados de espectroscopia IFU (Integral Field Units) reduzidos, mas os resultados da an\u00e1lise dos dados mostrando mapas de v\u00e1rias quantidades f\u00edsicas derivadas dos espectros. Para mais informa\u00e7\u00f5es consulte os tutoriais no site do portal MaNGA.","title":"MaNGA Portal"},{"location":"sci-platforms/sci_server.html","text":"O LIneA Science Server \u00e9 um servi\u00e7o de visualiza\u00e7\u00e3o de imagens e dados de cat\u00e1logos que foi inicialmente desenvolvido no contexto do levantamento DES, mas continua em desenvolvimento e est\u00e1 recebendo melhorias para operar na era do LSST. O LIneA Science Server ser\u00e1 a principal ferramenta de visualiza\u00e7\u00e3o de dados oferecida pelo IDAC-Brasil. Sky viewer \u00b6 Oferece exibi\u00e7\u00e3o panor\u00e2mica das imagens do DES, combinadas para formar uma imagem \u00fanica limitada apenas pelas bordas do footprint , e de mapas em formato HEALPix . Target viewer \u00b6 Ferramenta para visualizar e manipular imagens de uma lista de objetos previamente definida ( targets ). Oferece a possibilidade de rankear imagens, aplicar filtros baseados em propriedades dos objetos e criar mosaicos com m\u00faltiplas imagens. Tile Viewer \u00b6 Oferece a visualiza\u00e7\u00e3o das imagens do DES com exibi\u00e7\u00e3o baseada nas Tiles , a unidade de \u00e1rea adotada pelo levantamento. O Tile Viewer foi amplamente utilizado na inspe\u00e7\u00e3o e valida\u00e7\u00e3o dos dados nos per\u00edodos que antecederam os data releases internos e p\u00fablicos. Apoio ao usu\u00e1rio \u00b6 Tutoriais em v\u00eddeo \u00b6 O site do LIneA Science Server possui uma p\u00e1gina de tutoriais em v\u00eddeos, com narra\u00e7\u00e3o em ingl\u00eas, com exemplos de uso das ferramentas. Acesse os v\u00eddeos em: https://scienceserver.linea.org.br/tutorials Minicurso \u00b6 Como parte das atividades do programa de Inicia\u00e7\u00e3o Cient\u00edfica (IC), em 2022 o LIneA ofereceu uma s\u00e9rie de minicursos para os estudantes e demais interessados com aulas remotas e atividades pr\u00e1ticas propostas. Os v\u00eddeos das aulas est\u00e3o dispon\u00edveis na p\u00e1gina do Minicurso LIneA Science Server no Google Classroom.","title":"Science Server"},{"location":"sci-platforms/sci_server.html#sky-viewer","text":"Oferece exibi\u00e7\u00e3o panor\u00e2mica das imagens do DES, combinadas para formar uma imagem \u00fanica limitada apenas pelas bordas do footprint , e de mapas em formato HEALPix .","title":"Sky viewer"},{"location":"sci-platforms/sci_server.html#target-viewer","text":"Ferramenta para visualizar e manipular imagens de uma lista de objetos previamente definida ( targets ). Oferece a possibilidade de rankear imagens, aplicar filtros baseados em propriedades dos objetos e criar mosaicos com m\u00faltiplas imagens.","title":"Target viewer"},{"location":"sci-platforms/sci_server.html#tile-viewer","text":"Oferece a visualiza\u00e7\u00e3o das imagens do DES com exibi\u00e7\u00e3o baseada nas Tiles , a unidade de \u00e1rea adotada pelo levantamento. O Tile Viewer foi amplamente utilizado na inspe\u00e7\u00e3o e valida\u00e7\u00e3o dos dados nos per\u00edodos que antecederam os data releases internos e p\u00fablicos.","title":"Tile Viewer"},{"location":"sci-platforms/sci_server.html#apoio-ao-usuario","text":"","title":"Apoio ao usu\u00e1rio"},{"location":"sci-platforms/sci_server.html#tutoriais-em-video","text":"O site do LIneA Science Server possui uma p\u00e1gina de tutoriais em v\u00eddeos, com narra\u00e7\u00e3o em ingl\u00eas, com exemplos de uso das ferramentas. Acesse os v\u00eddeos em: https://scienceserver.linea.org.br/tutorials","title":"Tutoriais em v\u00eddeo"},{"location":"sci-platforms/sci_server.html#minicurso","text":"Como parte das atividades do programa de Inicia\u00e7\u00e3o Cient\u00edfica (IC), em 2022 o LIneA ofereceu uma s\u00e9rie de minicursos para os estudantes e demais interessados com aulas remotas e atividades pr\u00e1ticas propostas. Os v\u00eddeos das aulas est\u00e3o dispon\u00edveis na p\u00e1gina do Minicurso LIneA Science Server no Google Classroom.","title":"Minicurso"},{"location":"sci-platforms/sso.html","text":"O estudo de pequenos corpos no Sistema Solar apresenta desafios consider\u00e1veis, principalmente devido aos seus pequenos tamanhos e vastas dist\u00e2ncias. Um m\u00e9todo para superar esses obst\u00e1culos envolve estudos indiretos atrav\u00e9s de uma t\u00e9cnica conhecida como oculta\u00e7\u00e3o estelar. Historicamente, a predi\u00e7\u00e3o precisa destes eventos se provou ser dif\u00edcil devido \u00e0 falta de mapas estelares suficientemente precisos. No entanto, os avan\u00e7os recentes transformaram esta cen\u00e1rio, permitindo predi\u00e7\u00f5es de oculta\u00e7\u00f5es estelares altamente precisas para corpos do Sistema Solar. A t\u00e9cnica de oculta\u00e7\u00e3o estelar \u00e9 uma ferramenta crucial para estudar estes corpos, especialmente os TNOs, oferecendo informa\u00e7\u00f5es precisas sobre os seus tamanhos e posi\u00e7\u00f5es, bem como sobre o seu entorno, gra\u00e7as a uma das caracter\u00edsticas mais marcante da t\u00e9cnica: a tradu\u00e7\u00e3o de alta resolu\u00e7\u00e3o temporal em alta resolu\u00e7\u00e3o angular. Dado o esperado aumento de dez vezes no volume de dados do Sistema Solar a partir do Legacy Survey of Space and Time (LSST), o Portal do Sistema Solar pretende ser uma solu\u00e7\u00e3o de computa\u00e7\u00e3o de alto desempenho que prev\u00ea, organiza e distribui esses eventos, tornando-os globalmente acess\u00edveis para a comunidade, ao mesmo tempo que alivia a carga computacional. Este portal est\u00e1 divido entre uma interface p\u00fablica e uma inteface destinada a usu\u00e1rios membros. Para acessar todas as predi\u00e7\u00f5es de oculta\u00e7\u00f5es p\u00fablicas acesse o LIneA Occultation Prediction Database e para uso avan\u00e7ado da plataforma consulte a documenta\u00e7\u00e3o . O LIneA Solar System Portal \u00e9 destinado aos membros da colabora\u00e7\u00e3o Transneptunian Occultation Network (TON). Clique aqui para saber mais sobre a TON.","title":"Solar System Portal"},{"location":"sci-platforms/user_query.html","text":"Em breve! (servi\u00e7o em desenvolvimento) O User Query \u00e9 uma interface amig\u00e1vel para consultas ao banco de dados que vai possibilitar a cria\u00e7\u00e3o de tabelas tempor\u00e1rias com resultados imediatamente dispon\u00edveis para visualiza\u00e7\u00e3o no Target Viewer . Uma vers\u00e3o preliminar do User Query est\u00e1 dispon\u00edvel dentro do site \"espelho\" do LIneA Science Server que est\u00e1 hospedado no NCSA , acess\u00edvel apenas para membros da colabora\u00e7\u00e3o DES. Uma nova implementa\u00e7\u00e3o est\u00e1 sendo preparada com base no software Daiquiri e estar\u00e1 dispon\u00edvel em breve para os todos os usu\u00e1rios do LIneA Science Platform.","title":"User Query"}]}